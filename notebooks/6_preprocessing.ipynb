{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SequentialFeatureSelector\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SelectFromModel\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_importance, plot_tree\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/xgboost/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective, dask\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     Booster,\n\u001b[1;32m     10\u001b[0m     DataIter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     build_info,\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/xgboost/tracker.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, make_jcargs\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/xgboost/core.py:58\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     38\u001b[0m     _T,\n\u001b[1;32m     39\u001b[0m     ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     c_bst_ulong,\n\u001b[1;32m     57\u001b[0m )\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PANDAS_INSTALLED, DataFrame, import_cupy, py_str\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_lib_path\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mXGBoostError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/xgboost/compat.py:34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# pandas\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame, MultiIndex, Series\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat \u001b[38;5;28;01mas\u001b[39;00m pandas_concat\n\u001b[1;32m     37\u001b[0m     PANDAS_INSTALLED \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/pandas/__init__.py:138\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28meval\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    122\u001b[0m     concat,\n\u001b[1;32m    123\u001b[0m     lreshape,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m     qcut,\n\u001b[1;32m    136\u001b[0m )\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m testing\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_print_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/pandas/api/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" public toolkit API \"\"\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     extensions,\n\u001b[1;32m      4\u001b[0m     indexers,\n\u001b[1;32m      5\u001b[0m     interchange,\n\u001b[1;32m      6\u001b[0m     types,\n\u001b[1;32m      7\u001b[0m     typing,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterchange\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextensions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtyping\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/pandas/api/typing/__init__.py:31\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwindow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     Expanding,\n\u001b[1;32m     21\u001b[0m     ExpandingGroupby,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     Window,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# TODO: Can't import Styler without importing jinja2\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# from pandas.io.formats.style import Styler\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_json\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JsonReader\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StataReader\n\u001b[1;32m     34\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrameGroupBy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatetimeIndexResamplerGroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindow\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     55\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/pandas/io/json/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_json\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     read_json,\n\u001b[1;32m      3\u001b[0m     to_json,\n\u001b[1;32m      4\u001b[0m     ujson_dumps,\n\u001b[1;32m      5\u001b[0m     ujson_loads,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_table_schema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_table_schema\n\u001b[1;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson_dumps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson_loads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_table_schema\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/pandas/io/json/_json.py:71\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_normalize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_to_line_delimits\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_table_schema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     68\u001b[0m     build_table_schema,\n\u001b[1;32m     69\u001b[0m     parse_table_schema,\n\u001b[1;32m     70\u001b[0m )\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_integer\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     75\u001b[0m         Hashable,\n\u001b[1;32m     76\u001b[0m         Mapping,\n\u001b[1;32m     77\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/pandas/io/parsers/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     TextFileReader,\n\u001b[1;32m      3\u001b[0m     TextParser,\n\u001b[1;32m      4\u001b[0m     read_csv,\n\u001b[1;32m      5\u001b[0m     read_fwf,\n\u001b[1;32m      6\u001b[0m     read_table,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextFileReader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextParser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_fwf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_table\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/pandas/io/parsers/readers.py:32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m using_copy_on_write\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m STR_NA_VALUES\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m     AbstractMethodError,\n\u001b[1;32m     35\u001b[0m     ParserWarning,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Appender\n",
      "File \u001b[0;32mparsers.pyx:1418\u001b[0m, in \u001b[0;36minit pandas._libs.parsers\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import plot_importance, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Metrik wurde eine angepasste Version der Root Mean Squared Percentage Error (RMSPE)-Funktion implementiert. Um mathematische Probleme bei der Berechnung zu vermeiden, werden Datenpunkte mit Verkaufszahlen von null ignoriert, da eine Division durch null zu fehlerhaften Ergebnissen führen würde. Die Funktion berechnet den prozentualen Fehler nur für relevante Datenpunkte und liefert somit eine präzise Einschätzung der Modellgüte. Zusätzlich wird RMSPE als Scoring-Funktion mittels make_scorer in scikit-learn definiert, wobei geringere Werte auf eine bessere Modellleistung hinweisen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Angepasste RMSPE-Funktion, die Tage mit 0 Sales ignoriert\n",
    "def rmspe(y_true, y_pred):\n",
    "    # Nur Fälle berücksichtigen, bei denen y_true nicht 0 ist\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    \n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSPE als Scorer definieren\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimeSeries Kreuzvalidierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Kreuzvalidierungsmethode wurde ein TimeSeriesSplit aus der Bibliothek scikit-learn implementiert. Dies gewährleistet, dass die zeitliche Abfolge der Daten gewahrt bleibt, indem der Datensatz in aufeinanderfolgende Trainings- und Test-Splits unterteilt wird. So wird das Modell nur auf Vergangenheitsdaten trainiert und auf zukünftigen Daten evaluiert, was notwendig für Zeitreihendaten ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "# Zeitreihen-Kreuzvalidierung einrichten\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einlesen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz wird mit pd.read_csv() aus der Datei geladen. Dabei werden Kommata als Trennzeichen, Latein-1 als Encoding, sowie Tausender- und Dezimaltrennzeichen korrekt verarbeitet. low_memory=False stellt sicher, dass der Datensatz in einem Schritt eingelesen wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden des Datensatzes\n",
    "data_cleaned = \"../data/cleaned_train.csv\"\n",
    "data = pd.read_csv(data_cleaned, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!müssen begründen warum diese features!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'fourier_sin_365', 'fourier_cos_365',\t'days_since_last_holiday',\t'days_until_next_holiday'] # lag_1, lag_7 entfernt\n",
    "\n",
    "# Bereits encodierte Features\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "\n",
    "# Noch nicht encodierte kategorische Features\n",
    "categorical_features_to_encode = ['DayOfWeek', 'StoreType', 'StateHoliday','Assortment', 'Store'] # 'Store' entfernt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der folgende Code beschreibt die Aufteilung der Daten in einen Trainings- und Testdatensatz zur Vorbereitung für maschinelles Lernen. Zunächst wird der Datensatz anhand der Spalte „Date“ sortiert, um sicherzustellen, dass die zeitliche Reihenfolge der Datenpunkte korrekt ist. Dies ist  notwendig,da es sich um eine Zeitreihenanalyse handelt, bei der die Reihenfolge der Daten für die Genauigkeit der Vorhersage entscheidend ist.\n",
    "\n",
    "Zusätzlich werden alle Einträge, bei denen der Store geschlossen war (Open == 0) oder bei denen keine Verkäufe (Sales > 0) stattfanden, aus dem Datensatz entfernt. Diese Filterung sorgt dafür, dass das Modell nur auf den relevanten Daten trainiert wird, bei denen der Store tatsächlich offen war und Verkäufe getätigt wurden. Dies verbessert die Qualität der Daten und reduziert das Risiko von Fehlprognosen aufgrund irrelevanter oder fehlender Werte.\n",
    "\n",
    "Im nächsten Schritt wird die Zielvariable „Sales“ festgelegt. Sie wird separat als y definiert, da sie die zu prognostizierenden Werte enthält. Gleichzeitig werden die Spalten „Sales“ und „Date“ aus den Features (X) entfernt, da „Sales“ die Zielgröße ist und „Date“ in diesem Kontext keine erklärende Variable darstellt. Dies hilft, das Modell auf die relevanten Merkmale des Datensatzes zu reduzieren.\n",
    "\n",
    "Zuletzt erfolgt die Aufteilung des Datensatzes in Trainings- und Testdaten. Die ersten 80 % der Daten werden für das Training des Modells verwendet, während die letzten 20 % als Testdaten reserviert werden, um das Modell auf noch nicht gesehenen Daten zu evaluieren. Dieser Ansatz, bei dem die Testdaten aus den letzten Datenpunkten bestehen, ist besonders sinnvoll für zeitbasierte Modelle, da zukünftige Werte auf Grundlage vergangener Ereignisse vorhergesagt werden sollen. Die folgende Abbildung visualisiert diesen Split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz sortieren, falls nicht bereits geschehen (angenommen, du hast eine Spalte 'Date')\n",
    "data = data.sort_values('Date')\n",
    "\n",
    "# auch noch Text hinzufügen\n",
    "data = data[data ['Open']!=0]\n",
    "data = data[data ['Sales']>0]\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = data.drop(['Sales', 'Date', 'Open'], axis=1)  # 'Date' wird entfernt, wenn es keine erklärende Variable ist\n",
    "y = data['Sales']\n",
    "\n",
    "# Berechnung der Anzahl der Testdaten (20 % des Datensatzes)\n",
    "test_size = int(len(data) * 0.2)\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "X_train, X_test = X.iloc[:-test_size], X.iloc[-test_size:]\n",
    "y_train, y_test = y.iloc[:-test_size], y.iloc[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdates\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmdates\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/pandas/__init__.py:138\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28meval\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    122\u001b[0m     concat,\n\u001b[1;32m    123\u001b[0m     lreshape,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m     qcut,\n\u001b[1;32m    136\u001b[0m )\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m testing\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_print_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/pandas/api/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" public toolkit API \"\"\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     extensions,\n\u001b[1;32m      4\u001b[0m     indexers,\n\u001b[1;32m      5\u001b[0m     interchange,\n\u001b[1;32m      6\u001b[0m     types,\n\u001b[1;32m      7\u001b[0m     typing,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterchange\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextensions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtyping\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/pandas/api/typing/__init__.py:31\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwindow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     Expanding,\n\u001b[1;32m     21\u001b[0m     ExpandingGroupby,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     Window,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# TODO: Can't import Styler without importing jinja2\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# from pandas.io.formats.style import Styler\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_json\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JsonReader\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StataReader\n\u001b[1;32m     34\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrameGroupBy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatetimeIndexResamplerGroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindow\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     55\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/pandas/io/json/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_json\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     read_json,\n\u001b[1;32m      3\u001b[0m     to_json,\n\u001b[1;32m      4\u001b[0m     ujson_dumps,\n\u001b[1;32m      5\u001b[0m     ujson_loads,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_table_schema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_table_schema\n\u001b[1;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson_dumps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson_loads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_table_schema\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/pandas/io/json/_json.py:71\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_normalize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_to_line_delimits\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_table_schema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     68\u001b[0m     build_table_schema,\n\u001b[1;32m     69\u001b[0m     parse_table_schema,\n\u001b[1;32m     70\u001b[0m )\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_integer\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     75\u001b[0m         Hashable,\n\u001b[1;32m     76\u001b[0m         Mapping,\n\u001b[1;32m     77\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/pandas/io/parsers/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     TextFileReader,\n\u001b[1;32m      3\u001b[0m     TextParser,\n\u001b[1;32m      4\u001b[0m     read_csv,\n\u001b[1;32m      5\u001b[0m     read_fwf,\n\u001b[1;32m      6\u001b[0m     read_table,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextFileReader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextParser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_fwf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_table\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rossmann/lib/python3.12/site-packages/pandas/io/parsers/readers.py:32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m using_copy_on_write\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m STR_NA_VALUES\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m     AbstractMethodError,\n\u001b[1;32m     35\u001b[0m     ParserWarning,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Appender\n",
      "File \u001b[0;32mparsers.pyx:1418\u001b[0m, in \u001b[0;36minit pandas._libs.parsers\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# Konvertiere die 'Date'-Spalte in datetime mit der .loc Methode\n",
    "X_train.loc[:, 'Date'] = pd.to_datetime(X_train['Date'], errors='coerce')\n",
    "X_test.loc[:, 'Date'] = pd.to_datetime(X_test['Date'], errors='coerce')\n",
    "\n",
    "# Liniendiagramm erstellen, um die wahren Sales in y_train und y_test zu visualisieren\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot für die Trainingsdaten (y_train)\n",
    "plt.plot(X_train['Date'], y_train, label='Train (y_train)', color='blue', alpha=0.7)\n",
    "\n",
    "# Plot für die Testdaten (y_test)\n",
    "plt.plot(X_test['Date'], y_test, label='Test (y_test)', color='orange', alpha=0.7)\n",
    "\n",
    "# Achsenbeschriftungen\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Sales über die Zeit (Train und Test Split)')\n",
    "\n",
    "# X-Achse mit Datumsformatierung (Monat und Jahr)\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "\n",
    "plt.xticks(rotation=45)  # Drehe die x-Achsenbeschriftung für bessere Lesbarkeit\n",
    "\n",
    "# Legende\n",
    "plt.legend()\n",
    "\n",
    "# Layout anpassen und Diagramm anzeigen\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Preprocessing wird ein ColumnTransformer verwendet, um numerische, bereits encodierte und noch nicht encodierte kategoriale Merkmale eines Datensatzes gezielt zu transformieren. Dieser Schritt ist essenziell, um eine konsistente und effektive Vorbereitung der Daten zu gewährleisten.\n",
    "\n",
    "Die numerischen Merkmale, die in der Liste numerical_features enthalten sind, umfassen Variablen wie year, month, day, week_of_year, sowie Lag-Features (lag_1, lag_7, lag_30), Fourier-Transformationen zur Erfassung saisonaler Zyklen und Variablen zur Berücksichtigung von Feiertagen. Diese werden mit dem StandardScaler standardisiert, um sicherzustellen, dass alle numerischen Werte auf einen einheitlichen Maßstab gebracht werden.\n",
    "\n",
    "Bereits One-Hot-encodierte Merkmale (already_encoded_features) wie Open, Promo und promo2 werden ohne weitere Transformation mit 'passthrough' durchgeschleust. Diese Variablen wurden entweder schon in vorherigen Schritten in eine geeignete Form gebracht oder bedürfen keiner weiteren Skalierung oder Encodierung.\n",
    "\n",
    "Die noch nicht encodierten kategorialen Merkmale, wie DayOfWeek, StoreType, StateHoliday und Assortment, werden mittels OneHotEncoder in binäre Merkmale umgewandelt. Dies gewährleistet, dass jedes Merkmal durch eine Reihe von Spalten dargestellt wird, die angeben, ob eine bestimmte Kategorie vorliegt. Um potenziell unbekannte Kategorien in den Testdaten zu berücksichtigen, wird die Option handle_unknown='ignore' verwendet, wodurch unbekannte Werte ignoriert werden, ohne einen Fehler zu verursachen.\n",
    "\n",
    "Durch diesen modularen Ansatz werden die numerischen und kategorialen Features des Datensatzes effizient für das Training des Machine-Learning-Modells vorbereitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle den Preprocessor für numerische und kategorische Features (ohne Datumsextraktion)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),  # Skalierung für numerische und bereits encodierte Features\n",
    "        ('enc', 'passthrough', already_encoded_features),  # Bereits encodierte Features durchschleusen (keine weitere Transformation)\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)  # Nur noch nicht encodierte Features encodieren\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag-Features (bitte alle ausprobieren) - nachher bei jedem im eigenen Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #pipeline mit preprocessor & model definieren\n",
    "# Pipeline für die Modellierung\n",
    "pipeline  = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Schritt 1: Vorverarbeitung\n",
    "    ('model', ... )  # Schritt 3: Modellierung\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbesserte iterative Vorhersagefunktion (mit Berücksichtigung von Lag- und zusätzlichen Features)\n",
    "def iterative_forecast(pipeline, X_fold_train, y_fold_train, X_fold_val):\n",
    "    # Trainiere das Modell mit allen Features\n",
    "    pipeline.named_steps['model'].fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Vorhersagen auf Basis der Testdaten\n",
    "    predictions = []\n",
    "    last_known_sales = list(y_fold_train[-7:])  # Letzte 30 Tage tatsächlicher Sales-Daten\n",
    "    \n",
    "    # Iteriere über die Zeilen von X_fold_val\n",
    "    for index, row in X_fold_val.iterrows():\n",
    "        try:\n",
    "            # Lag-Features für den nächsten Tag berechnen\n",
    "            row[\"lag_1\"] = last_known_sales[-1]  # Lag-1 ist der zuletzt vorhergesagte Wert\n",
    "            row[\"lag_7\"] = last_known_sales[-7] if len(last_known_sales) >= 7 else np.nan  # Lag-7 ist 7 Tage zurück\n",
    "            #row[\"lag_30\"] = last_known_sales[-30] if len(last_known_sales) >= 30 else np.nan  # Lag-30 ist 30 Tage zurück\n",
    "        except IndexError as e:\n",
    "            print(f\"Error in creating lag features for row {index}: {e}\")\n",
    "            row[\"lag_1\"] = np.nan\n",
    "            row[\"lag_7\"] = np.nan\n",
    "            #row[\"lag_30\"] = np.nan\n",
    "        \n",
    "        # Wandeln der Zeile in einen DataFrame, um den Preprocessing-Schritt durchzuführen\n",
    "        row = row.to_frame().T\n",
    "        \n",
    "        # Wende das Preprocessing an\n",
    "        row_preprocessed = pipeline.named_steps['preprocessor'].transform(row)\n",
    "        \n",
    "        # Vorhersage für den nächsten Tag\n",
    "        pred = pipeline.named_steps['model'].predict(row_preprocessed)\n",
    "        predictions.append(pred[0])  # pred ist ein Array, daher pred[0]\n",
    "        \n",
    "        # Update der letzten bekannten Sales-Daten\n",
    "        last_known_sales.append(pred[0])\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Durchführung der Kreuzvalidierung auf den Trainingsdaten\n",
    "rmspe_scores = []  # Liste zur Speicherung der RMSPE-Scores\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(X_train)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Train- und Testdaten für diesen Fold\n",
    "    X_fold_train = X_train.iloc[train_index]\n",
    "    X_fold_test = X_train.iloc[test_index]\n",
    "    y_fold_train = y_train.iloc[train_index]\n",
    "    y_fold_test = y_train.iloc[test_index]\n",
    "    \n",
    "    # Preprocessing auf die Train- und Testdaten anwenden\n",
    "    X_fold_train_preprocessed = pipeline.named_steps['preprocessor'].fit_transform(X_fold_train)\n",
    "    X_fold_test_preprocessed = pipeline.named_steps['preprocessor'].transform(X_fold_test)\n",
    "    \n",
    "    # Iterative Vorhersage über die Testperiode\n",
    "    y_pred = iterative_forecast(pipeline, X_fold_train_preprocessed, y_fold_train, X_fold_test)\n",
    "    \n",
    "    # RMSPE berechnen und speichern\n",
    "    rmspe_score = rmspe(y_fold_test, y_pred)\n",
    "    rmspe_scores.append(rmspe_score)\n",
    "    \n",
    "    print(f\"RMSPE for Fold {fold + 1}: {rmspe_score}\")\n",
    "\n",
    "# Gesamtergebnisse\n",
    "print(f\"Durchschnittliche RMSPE über alle Folds: {np.mean(rmspe_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potenzielle Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beste Features Sina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['quarter'] = data['Date'].dt.quarter\n",
    "\n",
    "def comp_months(df):\n",
    "    df['CompetitionOpen'] = 12 * (df.year - df.CompetitionOpenSinceYear) + (df.month - df.CompetitionOpenSinceMonth)\n",
    "    df['CompetitionOpen'] = df['CompetitionOpen'].map(lambda x: 0 if x < 0 else x).fillna(0)\n",
    "    \n",
    "comp_months(data)\n",
    "\n",
    "def check_promo_month(row):\n",
    "    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun',              \n",
    "                 7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "    try:\n",
    "        months = (row['PromoInterval'] or '').split(',')\n",
    "        if row['Promo2Open'] and month2str[row['Month']] in months:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "def promo_cols(df):\n",
    "    # Months since Promo2 was open\n",
    "    df['Promo2Open'] = 12 * (df.year - df.Promo2SinceYear) +  (df.week_of_year - df.Promo2SinceWeek)*7/30.5\n",
    "    df['Promo2Open'] = df['Promo2Open'].map(lambda x: 0 if x < 0 else x).fillna(0) * df['Promo2']\n",
    "    # Whether a new round of promotions was started in the current month\n",
    "    df['IsPromo2Month'] = df.apply(check_promo_month, axis=1) * df['Promo2']\n",
    "    \n",
    "promo_cols(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = [ 'month', 'day', 'week_of_year', 'Promo2Open', 'CompetitionDistance']\n",
    "\n",
    "# Bereits encodierte Features\n",
    "already_encoded_features = ['Promo', 'SchoolHoliday','promo2', 'Promo2', 'is_weekend']\n",
    "\n",
    "# Noch nicht encodierte kategorische Features\n",
    "categorical_features_to_encode = ['DayOfWeek', 'StoreType', 'Assortment', 'StateHoliday', 'quarter' ] \n",
    "\n",
    "# Erstelle den Preprocessor für numerische und kategorische Features (ohne Datumsextraktion)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),  # Skalierung für numerische und bereits encodierte Features\n",
    "        ('enc', 'passthrough', already_encoded_features),  # Bereits encodierte Features durchschleusen (keine weitere Transformation)\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)  # Nur noch nicht encodierte Features encodieren\n",
    "    ])\n",
    "\n",
    "import xgboost\n",
    "\n",
    "# Pipeline für die Modellierung\n",
    "pipeline_xgb = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Schritt 1: Vorverarbeitung\n",
    "   # ('feature_selection', SelectFromModel(estimator=xgboost.XGBRegressor(), threshold=0.000001, prefit=False)),  # Schritt 2: Merkmalsauswahl\n",
    "    ('model', xgboost.XGBRegressor())  # Schritt 3: Modellierung\n",
    "])\n",
    "\n",
    "pipeline_xgb.fit(X_train, y_train)\n",
    "\n",
    "cv_scores = cross_val_score(pipeline_xgb, X_train, y_train, cv=tscv, scoring=rmspe_scorer, verbose=True)\n",
    "\n",
    "mean_rmspe = np.mean(cv_scores)\n",
    "\n",
    "y_pred = pipeline_xgb.predict(X_test)\n",
    "test_rmspe = rmspe(y_test, y_pred)\n",
    "\n",
    "print(mean_rmspe)\n",
    "print(test_rmspe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSPE-Training: -0.3364188849229886\n",
    "RMSPE-Test 0.29434758604784933"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rossmann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
