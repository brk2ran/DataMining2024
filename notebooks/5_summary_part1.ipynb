{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zusammenfassung der Zwischenergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Festgelegte Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Auswahl weiterer Features für das Vorhersagemodell basiert auf ihrer logischen Relevanz und der Analyse ihrer Korrelation mit den Verkaufszahlen.\n",
    "\n",
    "Der Wochentag (DayOfWeek) hat oft einen erheblichen Einfluss auf die Verkäufe, da die Kaufgewohnheiten der Kunden je nach Wochentag variieren können. Beispielsweise gibt es mehr Einkäufe an Wochenenden. Daher wird der Wochentag in Liste der verwendbaren Merkmale aufgenommen.\n",
    "\n",
    "Das Merkmal Customers (Kundenanzahl) hingegen ist weniger geeignet. Diese Entscheidung basiert auf der Abwägung der Auswirkungen auf die Modellgenauigkeit und die Komplexität des Vorhersageprozesses. Die Einbeziehung dieses Features würde bedeuten, dass auch die Anzahl der Kunden für zukünftige Zeitpunkte vorhersagt werden müsste. Dies fügt eine zusätzliche Schicht von Komplexität hinzu, da nun zwei miteinander verknüpfte Vorhersagen getroffen werden müssten: die Anzahl der Kunden und darauf basierend die Verkaufszahlen. Die Vorhersage der Kundenanzahl würde zusätzliche Modelle oder Algorithmen erfordern, die ebenfalls eine gewisse Fehlerquote aufweisen. Diese Fehler würden sich in der Verkaufsprognose widerspiegeln und könnten die Genauigkeit des Verkaufsprognosemodells verringern. Durch den Ausschluss des Customers-Features wird eine potenzielle Fehlerquelle reduziert und der Fokus liegt auf direkt beobachtbaren und prognostizierbaren Merkmalen. Der bewusste Ausschluss dieses Features hilft dabei, die Vorhersagegenauigkeit zu maximieren und die Komplexität des Modells zu minimieren, was zu einem effizienteren und zuverlässigeren Vorhersagemodell führt.\n",
    "\n",
    "Ob ein Geschäft geöffnet oder geschlossen ist (Open), hat einen direkten Einfluss auf die Verkäufe. Geschäfte, die geschlossen sind, haben keine Verkäufe. Die Korrelationsmatrix zeigt erwartungsgemäß eine hohe Korrelation mit Sales, da Verkäufe nur an geöffneten Tagen stattfinden können.\n",
    "\n",
    "Promotionen (Promo) beeinflussen die Verkaufszahlen erheblich, indem sie mehr Kunden anziehen und den Umsatz steigern. Die Korrelationsmatrix weist darauf hin, dass Promotionen zu höheren Verkaufszahlen führen, da eine positive Korrelation mit Sales besteht.\n",
    "\n",
    "Feiertage (StateHoliday) beeinflussen das Einkaufsverhalten der Kunden, da an staatlichen Feiertagen Geschäfte geschlossen sein oder weniger Kunden haben könnten. Die Korrelation variiert je nach Art des Feiertags, zeigt aber signifikante Zusammenhänge.\n",
    "\n",
    "Unterschiedliche Store-Typen (StoreType) können unterschiedliche Verkaufsmuster haben. Größere Geschäfte oder spezielle Geschäftsmodelle könnten höhere Verkäufe generieren. Die Korrelationsmatrix zeigt, dass die Korrelation je nach Typ variiert, aber signifikante Korrelationen mit anderen wichtigen Features wie Promo bestehen.\n",
    "\n",
    "Die Wahl der zusätzlichen Features basiert auf ihrer logischen Relevanz und bisherigen Korrelationsanalysen. Features wie DayOfWeek, Open, Promo, StateHoliday und StoreType sind stark mit den Verkaufszahlen verbunden und bieten wertvolle Informationen zur Verbesserung der Modellgenauigkeit. Eine detaillierte Untersuchung der Korrelationen dieser Features mit Sales bestätigt ihre Bedeutung und rechtfertigt ihre Einbeziehung in das Vorhersagemodell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Änderungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausschluss von Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die relevanten Features für das Modell auszuwählen, wurden verschiedene Merkmale getestet, um deren Einfluss auf die Vorhersagegenauigkeit zu bewerten. Dabei zeigte sich, dass die **Lag-Features**, die Genauigkeit des Modells erheblich verschlechterten. Aufgrund dieses negativen Effekts wurden diese Features in den weiteren Modellentwicklungen weggelassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittliche RMSPE (Cross-Validation): 1.7539\n",
      "Vorhersagen für die nächsten 60 Tage: [6868.0, 6235.0, 5694.0, 0.0, 0.0, 9615.0, 8180.0, 6480.0, 6328.0, 5470.0, 0.0, 4090.0, 3776.0, 3756.0, 3973.0, 3476.0, 3169.0, 0.0, 9615.0, 10744.0, 10041.0, 8735.0, 9165.0, 8373.0, 0.0, 15301.0, 25107.0, 16837.0, 18127.0, 16058.0, 16077.0, 0.0, 8324.0, 8328.0, 8328.0, 6355.0, 6594.0, 6588.0, 0.0, 4090.0, 3646.0, 3309.0, 2723.0, 3333.0, 2685.0, 0.0, 9615.0, 10311.0, 10216.0, 8735.0, 9165.0, 8373.0, 0.0, 4090.0, 3646.0, 3309.0, 2930.0, 3848.0, 4086.0, 0.0]\n",
      "RMSPE der Vorhersagen für die nächsten 60 Tage: 0.9235\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# RMSPE Funktion definieren\n",
    "def rmspe(y_true, y_pred):\n",
    "    y_pred = np.array(y_pred)  # Umwandlung der Vorhersagen in ein Numpy-Array\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# RMSPE als Scorer definieren\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n",
    "\n",
    "# Laden des Datensatzes\n",
    "data_cleaned = \"../data/cleaned_train_alt.csv\"\n",
    "data = pd.read_csv(data_cleaned, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'lag_1', 'lag_7']\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "categorical_features_to_encode = ['Store', 'DayOfWeek', 'StoreType', 'StateHoliday', 'Assortment']\n",
    "\n",
    "# Preprocessing Pipeline für numerische und kategorische Features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('enc', 'passthrough', already_encoded_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)\n",
    "    ])\n",
    "\n",
    "# Modell für RandomForest erstellen\n",
    "model = RandomForestRegressor(n_estimators=1, random_state=42)\n",
    "\n",
    "# Pipeline erstellen\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "#Funktion zur Vorhersage der nächsten x Tage (wie im Originalcode)\n",
    "def predict_multiple_days_with_updates(X_last, test_data, num_days):\n",
    "    predictions = []\n",
    "    X_next = X_last.copy()\n",
    "    X_next = pd.DataFrame([X_next])  # In DataFrame umwandeln\n",
    "    last_lags = list(X_last[['lag_1']].values.flatten())  # Initialisiere letzte Lags\n",
    "\n",
    "    for day in range(num_days):\n",
    "        # Preprocess die Daten vor der Vorhersage\n",
    "        X_next_preprocessed = pipeline.named_steps['preprocessor'].transform(X_next)\n",
    "        \n",
    "        # Vorhersage des nächsten Tages\n",
    "        y_next_pred = pipeline.named_steps['model'].predict(X_next_preprocessed)[0]\n",
    "        predictions.append(y_next_pred)\n",
    "\n",
    "        # Aktualisiere die Lag-Features basierend auf der Vorhersage\n",
    "        last_lags.append(y_next_pred)\n",
    "        last_lags.pop(0)  # Aktualisiere Lag-Werte\n",
    "\n",
    "        X_next.loc[:, 'lag_1'] = y_next_pred\n",
    "        X_next.loc[:, 'lag_7'] = last_lags[0]\n",
    "\n",
    "        # Aktualisiere andere Features (Tag, Monat, Woche)\n",
    "        X_next.loc[:, 'day'] += 1\n",
    "        if X_next.loc[:, 'day'].values[0] > 31:\n",
    "            X_next.loc[:, 'day'] = 1\n",
    "            X_next.loc[:, 'month'] += 1\n",
    "        if X_next.loc[:, 'month'].values[0] > 12:\n",
    "            X_next.loc[:, 'month'] = 1\n",
    "            X_next.loc[:, 'year'] += 1\n",
    "\n",
    "        X_next.loc[:, 'week_of_year'] = (X_next['week_of_year'] % 52) + 1\n",
    "        X_next.loc[:, 'DayOfWeek'] = (X_next['DayOfWeek'] % 7) + 1\n",
    "\n",
    "        # Promo- und andere Features aus Testdaten übernehmen\n",
    "        if day < len(test_data):\n",
    "            X_next.loc[:, 'Promo'] = test_data.iloc[day]['Promo']\n",
    "            X_next.loc[:, 'Open'] = test_data.iloc[day]['Open']\n",
    "            X_next.loc[:, 'StateHoliday'] = test_data.iloc[day]['StateHoliday']\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# TimeSeriesSplit für Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Überprüfung mit Cross-Validation\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "cv_rmspe_scores = []\n",
    "for train_idx, test_idx in tscv.split(X_train):\n",
    "    X_train_cv, X_test_cv = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Pipeline auf den Cross-Validation-Trainingsdaten fitten\n",
    "    pipeline.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    # Lag-Feature-Vorhersage für die CV-Testdaten\n",
    "    X_last_cv = X_test_cv.iloc[0]  # Starte mit dem ersten Testtag\n",
    "    num_days_cv = len(X_test_cv)    # Vorhersage für alle Testtage\n",
    "    future_predictions_cv = predict_multiple_days_with_updates(X_last_cv, X_test_cv, num_days_cv)\n",
    "\n",
    "    # Berechne RMSPE für diesen Split\n",
    "    rmspe_score = rmspe(y_test_cv.values, future_predictions_cv)\n",
    "    cv_rmspe_scores.append(rmspe_score)\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "mean_cv_rmspe = np.mean(cv_rmspe_scores)\n",
    "print(f\"Durchschnittliche RMSPE (Cross-Validation): {mean_cv_rmspe:.4f}\")\n",
    "\n",
    "# Nimm die letzten Daten als Startpunkt für die Vorhersage\n",
    "X_last = X_test.iloc[-60]\n",
    "\n",
    "# Vorhersage für die nächsten 7 Tage unter Verwendung von Promo-Informationen aus dem Testdatensatz\n",
    "num_days = 60\n",
    "test_data_next_days = X_test.iloc[:num_days]  # Extrahiere die Testdaten für die nächsten Tage\n",
    "\n",
    "# Vorhersagen für die nächsten Tage machen\n",
    "future_predictions = predict_multiple_days_with_updates(X_last, test_data_next_days, num_days)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(f\"Vorhersagen für die nächsten {num_days} Tage:\", future_predictions)\n",
    "\n",
    "# Tatsächliche Verkaufszahlen für die nächsten 7 Tage aus dem Testdatensatz extrahieren\n",
    "actual_sales_next_days = y_test.iloc[:num_days].values\n",
    "\n",
    "# Berechnung der RMSPE für die Vorhersagen\n",
    "prediction_rmspe = rmspe(actual_sales_next_days, future_predictions)\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "print(f\"RMSPE der Vorhersagen für die nächsten {num_days} Tage: {prediction_rmspe:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neue Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch zuvor erwähnten Tests der unterschiedlichen Feature-Kombinationen wurde der Einfluss der einzelnen Variablen auf die Modellleistung ermittelt. Basierend auf diesen Erkenntnissen wurden die finalen Features für das Modell festgelegt, da sie die bestmögliche Leistung ohne weitere Optimierungen erreichten.\n",
    "\n",
    "Die Zeitmerkmale Jahr, Monat, Tag und Woche des Jahres helfen dabei, saisonale Trends und zeitabhängige Muster zu erfassen. Verkäufe variieren häufig in bestimmten Monaten oder Jahreszeiten, was die Vorhersagegenauigkeit deutlich erhöht. Die Verwendung von Fourier-Transformationen, speziell die Fourier-Sin- und Fourier-Cos-Funktionen für 365 Tage, ermöglicht es, saisonale Effekte auf kontinuierliche Weise zu modellieren. Diese Features sind besonders nützlich, um komplexe saisonale Muster zu identifizieren und verbessern die Robustheit der Vorhersagen.\n",
    "Die Merkmale `days_since_last_holiday` und `days_until_next_holiday` `wurden gewählt, da Feiertage oft einen signifikanten Einfluss auf die Verkaufszahlen haben. Diese zeitlichen Angaben helfen dem Modell, den Einfluss von Feiertagen auf den Verkauf in den relevanten Zeiträumen zu erfassen.\n",
    "\n",
    "`Promo` und `Promo2` geben an, ob während bestimmter Zeiträume Werbeaktionen durchgeführt werden. Promotionen haben häufig einen erheblichen Einfluss auf die Verkaufszahlen, und die Berücksichtigung dieser Merkmale ermöglicht es dem Modell, den Effekt von Rabatten auf die Verkaufsprognosen zu lernen.\n",
    "\n",
    "Verkaufszahlen variieren oft an verschiedenen Wochentagen, und die Codierung des Features `day_of_the_week` erlaubt es dem Modell, wöchentliche Muster zu erkennen. Das `StoreType`-Feature ist relevant, da die Art des Geschäfts einen Einfluss auf die Verkaufszahlen haben kann. Unterschiedliche Geschäftsmodelle ziehen unterschiedliche Kunden an und verfolgen variierende Verkaufsstrategien.\n",
    "\n",
    "Ein weiteres wichtiges Feature ist `StateHoliday`, das angibt, ob ein Feiertag vorliegt. Feiertage haben oft einen starken Einfluss auf den Einzelhandel, und das Modell kann lernen, diese Effekte zu berücksichtigen. Das `Assortment`-Feature, das die Produktvielfalt im Geschäft beschreibt, ist ebenfalls entscheidend, da unterschiedliche Sortimentstypen verschiedene Kunden anziehen und die Verkaufszahlen beeinflussen können. Schließlich liefert das `Store`-Feature Informationen über spezifische Geschäfte, was hilft, lokale Verkaufsunterschiede zu erfassen. Jedes Geschäft kann unterschiedliche Verkaufsleistungen aufweisen, die durch Faktoren wie Lage, Größe und Zielgruppe bedingt sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 1 - Train RMSPE: 0.4084, Test RMSPE: 0.3796\n",
      "n_estimators: 5 - Train RMSPE: 0.3983, Test RMSPE: 0.3716\n",
      "n_estimators: 10 - Train RMSPE: 0.3963, Test RMSPE: 0.3718\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Zusätzliche Features erstellen\n",
    "data['is_month_end'] = data['day'].isin([28, 29, 30, 31]).astype(int)\n",
    "data['is_quarter_end'] = data['month'].isin([3, 6, 9, 12]).astype(int)\n",
    "data['sin_day_of_week'] = np.sin(2 * np.pi * data['day_of_week'] / 7)\n",
    "data['cos_day_of_week'] = np.cos(2 * np.pi * data['day_of_week'] / 7)\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# Bestimme die Grenze für 80% Training und 20% Test\n",
    "train_size = int(len(df) * 0.8)\n",
    "# Aufteilen in Trainings- und Test-Datensätze\n",
    "train = df.iloc[:train_size]\n",
    "test = df.iloc[train_size:]\n",
    "\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'is_month_end','is_quarter_end', 'sin_day_of_week', 'cos_day_of_week']\n",
    "\n",
    "# Bereits encodierte Features\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "\n",
    "# Noch nicht encodierte kategorische Features\n",
    "categorical_features_to_encode = ['Store', 'DayOfWeek', 'StoreType', 'StateHoliday','Assortment']\n",
    "\n",
    "# Definiere einen Imputer für numerische Daten\n",
    "numerical_imputer = SimpleImputer(strategy='mean')  # Oder 'median', je nach Bedarf\n",
    "\n",
    "# Füge den Imputer zur Preprocessing-Pipeline hinzu\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[('imputer', numerical_imputer), ('scaler', StandardScaler())]), numerical_features+ already_encoded_features),\n",
    "        ('enc', 'passthrough', already_encoded_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# RMSPE Funktion definieren\n",
    "def rmspe(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# Scorer für Cross-Validation\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n",
    "\n",
    "# Daten in Training (80%) und Test (20%) aufteilen\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# TimeSeriesSplit für Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Teste verschiedene Werte für n_estimators\n",
    "n_estimators_range = [1, 5, 10, 20]\n",
    "train_rmspe_scores = []\n",
    "test_rmspe_scores = []\n",
    "\n",
    "for n in n_estimators_range:\n",
    "    # Erstelle die Pipeline mit dem aktuellen Wert für n_estimators\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestRegressor(n_estimators=n, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Cross-Validation auf dem Trainingsdatensatz durchführen\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=tscv, scoring=rmspe_scorer)\n",
    "    mean_cv_score = -np.mean(cv_scores)  # Da RMSPE negativ definiert ist\n",
    "    \n",
    "    # Trainiere das Modell auf dem gesamten Trainingsdatensatz\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Vorhersagen auf dem Testdatensatz\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Berechne RMSPE für den Testdatensatz\n",
    "    test_rmspe = rmspe(y_test, y_test_pred)\n",
    "    \n",
    "    # Speichere die Scores\n",
    "    train_rmspe_scores.append(mean_cv_score)\n",
    "    test_rmspe_scores.append(test_rmspe)\n",
    "    \n",
    "    # Ausgabe der Ergebnisse\n",
    "    print(f\"n_estimators: {n} - Train RMSPE: {mean_cv_score:.4f}, Test RMSPE: {test_rmspe:.4f}\")\n",
    "\n",
    "# Plotten der Ergebnisse\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_estimators_range, train_rmspe_scores, label='Train RMSPE (Cross-Validation)', marker='o')\n",
    "plt.plot(n_estimators_range, test_rmspe_scores, label='Test RMSPE', marker='o')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('RMSPE')\n",
    "plt.title('RMSPE vs. n_estimators (TimeSeriesSplit)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!!neue features ausprobiere\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['month', 'week_of_year', 'is_weekend', 'day_of_year', 'day_of_week']\n",
    "already_encoded_features = ['Promo', 'promo2']\n",
    "categorical_features_to_encode = ['StoreType', 'Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.40544973, -0.39666004, -0.41508695, -0.40354785, -0.40712357])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=tscv, scoring=rmspe_scorer, verbose=True)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.40557362686514165"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_rmspe = np.mean(cv_scores)\n",
    "mean_rmspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37880351499349507"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "test_rmspe = rmspe(y_test, y_pred)\n",
    "test_rmspe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
