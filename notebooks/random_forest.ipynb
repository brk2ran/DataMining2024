{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Laden des Datensatzes\n",
    "data_cleaned = \"../data/cleaned_train_alt.csv\"\n",
    "data = pd.read_csv(data_cleaned, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'lag_1', 'lag_7']\n",
    "\n",
    "# Bereits encodierte Features\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "\n",
    "# Noch nicht encodierte kategorische Features\n",
    "categorical_features_to_encode = ['Store', 'DayOfWeek', 'StoreType', 'StateHoliday','Assortment']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Datensatz aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angepasste RMSPE-Funktion, die Tage mit 0 Sales ignoriert\n",
    "def rmspe(y_true, y_pred):\n",
    "    # Nur Fälle berücksichtigen, bei denen y_true nicht 0 ist\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    \n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# RMSPE als Scorer definieren\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle den Preprocessor für numerische und kategorische Features (ohne Datumsextraktion)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features + already_encoded_features),  # Skalierung für numerische und bereits encodierte Features\n",
    "        ('enc', 'passthrough', already_encoded_features),  # Bereits encodierte Features durchschleusen (keine weitere Transformation)\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)  # Nur noch nicht encodierte Features encodieren\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest mit Pre-Processing Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSPE CV-Scores: [-0.16908628 -0.15583158 -0.30281814 -0.16420855 -0.24732529]\n",
      "Mean RMSPE: 0.20785396741046566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "# Erstelle die Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=40, random_state=42))\n",
    "])\n",
    "\n",
    "# Optional: Cross-Validation mit RMSPE als Scorer\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring=rmspe_scorer)\n",
    "\n",
    "print(f\"RMSPE CV-Scores: {cv_scores}\")\n",
    "print(f\"Mean RMSPE: {-np.mean(cv_scores)}\")  # Negative Werte, da greater_is_better=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSPE auf dem Testdatensatz: 0.14426840086304352\n"
     ]
    }
   ],
   "source": [
    "# Trainiere das Modell\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen auf dem Testdatensatz\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# RMSPE auf dem Testdatensatz berechnen\n",
    "rmspe_score = rmspe(y_test, y_pred)\n",
    "print(f\"RMSPE auf dem Testdatensatz: {rmspe_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [10, 50, 100, 200, 300, 400, 500]\n",
    "for e in estimators:\n",
    "    # Erstelle die Pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestRegressor(n_estimators=e, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Optional: Cross-Validation mit RMSPE als Scorer\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring=rmspe_scorer)\n",
    "    print(f\"n_estimators: {e}\")\n",
    "    print(f\"RMSPE CV-Scores: {cv_scores}\")\n",
    "    print(f\"Mean RMSPE: {-np.mean(cv_scores)}\")  # Negative Werte, da greater_is_better=False\n",
    "    # Trainiere das Modell\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Vorhersagen auf dem Testdatensatz\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # RMSPE auf dem Testdatensatz berechnen\n",
    "    rmspe_score = rmspe(y_test, y_pred)\n",
    "    print(f\"RMSPE auf dem Testdatensatz: {rmspe_score}\")\n",
    "\n",
    "    # Ausgabe der Ergebnisse\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Percentage Error (RMSPE): inf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# RMSPE-Funktion\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Datensatz laden\n",
    "data = pd.read_csv('/Users/marieernst/Documents/Master/2.Semester/DataMining/Projekt2/data/cleaned_train.csv')\n",
    "\n",
    "# Datum in datetime umwandeln\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Durchschnittlicher Verkauf der letzten 7 Tage\n",
    "data = data.sort_values(by=['Store', 'Date'])\n",
    "data['Sales_Lag_7'] = data.groupby('Store')['Sales'].shift(7)\n",
    "data['Sales_Rolling_7'] = data.groupby('Store')['Sales_Lag_7'].transform(lambda x: x.rolling(7).mean())\n",
    "\n",
    "# Feature Engineering\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Day'] = data['Date'].dt.day\n",
    "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
    "\n",
    "# NaN-Werte füllen\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Relevante Features definieren\n",
    "features = ['Store', 'DayOfWeek', 'Promo', 'Year', 'Month', 'Day', 'Sales_Rolling_7']\n",
    "X = data[features]\n",
    "y = data['Sales']\n",
    "\n",
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelltraining\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "error = rmspe(y_test, predictions)\n",
    "print(f'Root Mean Square Percentage Error (RMSPE): {error}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
