{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Laden des Datensatzes\n",
    "data_cleaned = \"../data/cleaned_train_alt.csv\"\n",
    "data = pd.read_csv(data_cleaned, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'lag_1', 'lag_7']\n",
    "\n",
    "# Bereits encodierte Features\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "\n",
    "# Noch nicht encodierte kategorische Features\n",
    "categorical_features_to_encode = ['Store', 'DayOfWeek', 'StoreType', 'StateHoliday','Assortment']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Datensatz aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Bestimme die Grenze für 80% Training und 20% Test\n",
    "train_size = int(len(df) * 0.8)\n",
    "\n",
    "# Aufteilen in Trainings- und Test-Datensätze\n",
    "train = df.iloc[:train_size]\n",
    "test = df.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angepasste RMSPE-Funktion, die Tage mit 0 Sales ignoriert\n",
    "def rmspe(y_true, y_pred):\n",
    "    # Nur Fälle berücksichtigen, bei denen y_true nicht 0 ist\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    \n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# RMSPE als Scorer definieren\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle den Preprocessor für numerische und kategorische Features (ohne Datumsextraktion)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features + already_encoded_features),  # Skalierung für numerische und bereits encodierte Features\n",
    "        ('enc', 'passthrough', already_encoded_features),  # Bereits encodierte Features durchschleusen (keine weitere Transformation)\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)  # Nur noch nicht encodierte Features encodieren\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest mit Pre-Processing Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 1 - Train RMSPE: 0.2424, Test RMSPE: 0.2644\n",
      "n_estimators: 5 - Train RMSPE: 0.2187, Test RMSPE: 0.2469\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m mean_cv_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(cv_scores)  \u001b[38;5;66;03m# Da RMSPE negativ definiert ist\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Trainiere das Modell auf dem gesamten Trainingsdatensatz\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Vorhersagen auf dem Testdatensatz\u001b[39;00m\n\u001b[1;32m     49\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py:475\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    474\u001b[0m         last_step_params \u001b[39m=\u001b[39m routed_params[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 475\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mlast_step_params[\u001b[39m\"\u001b[39;49m\u001b[39mfit\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    477\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    490\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    491\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    492\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    493\u001b[0m )(\n\u001b[1;32m    494\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    495\u001b[0m         t,\n\u001b[1;32m    496\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    497\u001b[0m         X,\n\u001b[1;32m    498\u001b[0m         y,\n\u001b[1;32m    499\u001b[0m         sample_weight,\n\u001b[1;32m    500\u001b[0m         i,\n\u001b[1;32m    501\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    502\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    503\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    504\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    505\u001b[0m         missing_values_in_feature_mask\u001b[39m=\u001b[39;49mmissing_values_in_feature_mask,\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    508\u001b[0m )\n\u001b[1;32m    510\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    190\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 192\u001b[0m     tree\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m    193\u001b[0m         X,\n\u001b[1;32m    194\u001b[0m         y,\n\u001b[1;32m    195\u001b[0m         sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight,\n\u001b[1;32m    196\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    197\u001b[0m         missing_values_in_feature_mask\u001b[39m=\u001b[39;49mmissing_values_in_feature_mask,\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     tree\u001b[39m.\u001b[39m_fit(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[39m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# RMSPE Funktion definieren\n",
    "def rmspe(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# Scorer für Cross-Validation\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n",
    "\n",
    "# Daten in Training (80%) und Test (20%) aufteilen\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# TimeSeriesSplit für Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Teste verschiedene Werte für n_estimators\n",
    "n_estimators_range = [1,5,10,20]\n",
    "train_rmspe_scores = []\n",
    "test_rmspe_scores = []\n",
    "\n",
    "for n in n_estimators_range:\n",
    "    # Erstelle die Pipeline mit dem aktuellen Wert für n_estimators\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestRegressor(n_estimators=n, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Cross-Validation auf dem Trainingsdatensatz durchführen\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=tscv, scoring=rmspe_scorer)\n",
    "    mean_cv_score = -np.mean(cv_scores)  # Da RMSPE negativ definiert ist\n",
    "    \n",
    "    # Trainiere das Modell auf dem gesamten Trainingsdatensatz\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Vorhersagen auf dem Testdatensatz\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Berechne RMSPE für den Testdatensatz\n",
    "    test_rmspe = rmspe(y_test, y_test_pred)\n",
    "    \n",
    "    # Speichere die Scores\n",
    "    train_rmspe_scores.append(mean_cv_score)\n",
    "    test_rmspe_scores.append(test_rmspe)\n",
    "    \n",
    "    # Ausgabe der Ergebnisse\n",
    "    print(f\"n_estimators: {n} - Train RMSPE: {mean_cv_score:.4f}, Test RMSPE: {test_rmspe:.4f}\")\n",
    "\n",
    "# Plotten der Ergebnisse\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_estimators_range, train_rmspe_scores, label='Train RMSPE (Cross-Validation)', marker='o')\n",
    "plt.plot(n_estimators_range, test_rmspe_scores, label='Test RMSPE', marker='o')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('RMSPE')\n",
    "plt.title('RMSPE vs. n_estimators (TimeSeriesSplit)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSPE CV-Scores: [-0.16908628 -0.15583158 -0.30281814 -0.16420855 -0.24732529]\n",
      "Mean RMSPE: 0.20785396741046566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "# Erstelle die Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=40, random_state=42))\n",
    "])\n",
    "\n",
    "# Optional: Cross-Validation mit RMSPE als Scorer\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring=rmspe_scorer)\n",
    "\n",
    "print(f\"RMSPE CV-Scores: {cv_scores}\")\n",
    "print(f\"Mean RMSPE: {-np.mean(cv_scores)}\")  # Negative Werte, da greater_is_better=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSPE auf dem Testdatensatz: 0.14426840086304352\n"
     ]
    }
   ],
   "source": [
    "# Trainiere das Modell\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen auf dem Testdatensatz\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# RMSPE auf dem Testdatensatz berechnen\n",
    "rmspe_score = rmspe(y_test, y_pred)\n",
    "print(f\"RMSPE auf dem Testdatensatz: {rmspe_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 10\n",
      "RMSPE CV-Scores: [-0.17075823 -0.15749867 -0.29701022 -0.1658843  -0.24551046]\n",
      "Mean RMSPE: 0.20733237824285541\n",
      "RMSPE auf dem Testdatensatz: 0.14675355789333175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimators = [10, 50, 100, 200, 300, 400, 500]\n",
    "for e in estimators:\n",
    "    # Erstelle die Pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestRegressor(n_estimators=e, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Optional: Cross-Validation mit RMSPE als Scorer\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring=rmspe_scorer)\n",
    "    print(f\"n_estimators: {e}\")\n",
    "    print(f\"RMSPE CV-Scores: {cv_scores}\")\n",
    "    print(f\"Mean RMSPE: {-np.mean(cv_scores)}\")  # Negative Werte, da greater_is_better=False\n",
    "   \n",
    "   # Trainiere das Modell\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Vorhersagen auf dem Testdatensatz\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # RMSPE auf dem Testdatensatz berechnen\n",
    "    rmspe_score = rmspe(y_test, y_pred)\n",
    "    print(f\"RMSPE auf dem Testdatensatz: {rmspe_score}\")\n",
    "\n",
    "    # Ausgabe der Ergebnisse\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest tageweise Vorhersage (aktuelle Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Percentage Error (RMSPE): inf\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# RMSPE Funktion definieren\n",
    "def rmspe(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# RMSPE als Scorer definieren\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n",
    "\n",
    "# Laden des Datensatzes\n",
    "data_cleaned = \"../data/cleaned_train_alt.csv\"\n",
    "data = pd.read_csv(data_cleaned, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'lag_1', 'lag_7']\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "categorical_features_to_encode = ['Store', 'DayOfWeek', 'StoreType', 'StateHoliday', 'Assortment']\n",
    "\n",
    "# Preprocessing Pipeline für numerische und kategorische Features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features + already_encoded_features),\n",
    "        ('enc', 'passthrough', already_encoded_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)\n",
    "    ])\n",
    "\n",
    "# Modell für RandomForest erstellen\n",
    "model = RandomForestRegressor(n_estimators=20, random_state=42)\n",
    "\n",
    "# Pipeline erstellen\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Funktion zur Vorhersage mehrerer Tage mit Feature-Update\n",
    "def predict_multiple_days_with_updates(X_last, num_days, feature_update_rules):\n",
    "    predictions = []\n",
    "    X_next = X_last.copy()\n",
    "    \n",
    "    for day in range(num_days):\n",
    "        # Vorhersage des nächsten Tages\n",
    "        y_next_pred = pipeline.predict([X_next])[0]\n",
    "        predictions.append(y_next_pred)\n",
    "        \n",
    "        # Aktualisiere die Lag-Features basierend auf der Vorhersage\n",
    "        X_next['lag_1'] = y_next_pred  # Verschiebe die vorhergesagte Sales als lag_1\n",
    "        X_next['lag_7'] = X_last['lag_1']  # Aktualisiere lag_7 mit den vorherigen lag_1 Werten\n",
    "        \n",
    "        # Aktualisiere andere Features gemäß den Regeln\n",
    "        X_next['day'] += 1  # Verschiebe den Tag\n",
    "        if X_next['day'] > 31:  # Beispiel: Überlauf des Tages\n",
    "            X_next['day'] = 1\n",
    "            X_next['month'] += 1  # Verschiebe den Monat bei Tageswechsel\n",
    "        if X_next['month'] > 12:  # Überlauf des Monats\n",
    "            X_next['month'] = 1\n",
    "            X_next['year'] += 1\n",
    "        \n",
    "        # Aktualisiere Wochenzahl\n",
    "        X_next['week_of_year'] = (X_next['week_of_year'] % 52) + 1\n",
    "        \n",
    "        # Aktualisiere den Tag der Woche\n",
    "        X_next['DayOfWeek'] = (X_next['DayOfWeek'] % 7) + 1\n",
    "        \n",
    "        # Update Promo, Open, StateHoliday etc. basierend auf Regeln\n",
    "        # Hier könnte man festlegen, wann Promo oder Feiertage kommen\n",
    "        \n",
    "        # Nutze die tatsächlichen zukünftigen Daten, falls vorhanden\n",
    "        if feature_update_rules.get('Promo'):\n",
    "            X_next['Promo'] = feature_update_rules['Promo'](X_next)\n",
    "\n",
    "        # Optionale Updates für andere Features (Promo, Feiertage etc.)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# TimeSeriesSplit für Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Überprüfung mit Cross-Validation\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "cv_rmspe_scores = []\n",
    "for train_idx, test_idx in tscv.split(X_train):\n",
    "    X_train_cv, X_test_cv = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    # Pipeline auf den Cross-Validation-Trainingsdaten fitten\n",
    "    pipeline.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # Vorhersage für den Testdatensatz\n",
    "    y_pred_cv = pipeline.predict(X_test_cv)\n",
    "    \n",
    "    # Berechne RMSPE für diesen Split\n",
    "    rmspe_score = rmspe(y_test_cv, y_pred_cv)\n",
    "    cv_rmspe_scores.append(rmspe_score)\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "mean_cv_rmspe = np.mean(cv_rmspe_scores)\n",
    "print(f\"Durchschnittliche RMSPE (Cross-Validation): {mean_cv_rmspe:.4f}\")\n",
    "\n",
    "# Nimm die letzten Daten als Startpunkt für die Vorhersage\n",
    "X_last = X_test.iloc[-1]\n",
    "\n",
    "# Beispiel: Definiere Regeln zur Aktualisierung von Promo\n",
    "feature_update_rules = {\n",
    "    'Promo': lambda X: 1 if (X['day'] % 7 == 0) else 0  # Beispielregel: Promo jeden 7. Tag\n",
    "}\n",
    "\n",
    "# Vorhersage für die nächsten 7 Tage\n",
    "num_days = 7\n",
    "future_predictions = predict_multiple_days_with_updates(X_last, num_days, feature_update_rules)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(f\"Vorhersagen für die nächsten {num_days} Tage:\", future_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Werte für Promo aus Testdatensatz verwendet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittliche RMSPE (Cross-Validation): 0.2424\n",
      "Vorhersagen für die nächsten 7 Tage: [9299.0, 9005.0, 8796.0, 0.0, 0.0, 8942.0, 8649.0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# RMSPE Funktion definieren\n",
    "def rmspe(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# RMSPE als Scorer definieren\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n",
    "\n",
    "# Laden des Datensatzes\n",
    "data_cleaned = \"../data/cleaned_train_alt.csv\"\n",
    "data = pd.read_csv(data_cleaned, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'lag_1', 'lag_7']\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "categorical_features_to_encode = ['Store', 'DayOfWeek', 'StoreType', 'StateHoliday', 'Assortment']\n",
    "\n",
    "# Preprocessing Pipeline für numerische und kategorische Features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features + already_encoded_features),\n",
    "        ('enc', 'passthrough', already_encoded_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)\n",
    "    ])\n",
    "\n",
    "# Modell für RandomForest erstellen\n",
    "model = RandomForestRegressor(n_estimators=1, random_state=42)\n",
    "\n",
    "# Pipeline erstellen\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Funktion zur Vorhersage mehrerer Tage mit Feature-Update\n",
    "def predict_multiple_days_with_updates(X_last, test_data, num_days):\n",
    "    predictions = []\n",
    "    X_next = X_last.copy()\n",
    "\n",
    "    # Wandle X_next in ein DataFrame um, falls es keine DataFrame ist\n",
    "    X_next = pd.DataFrame([X_next])\n",
    "\n",
    "    for day in range(num_days):\n",
    "        # Vorhersage des nächsten Tages\n",
    "        y_next_pred = pipeline.predict(X_next)[0]\n",
    "        predictions.append(y_next_pred)\n",
    "        \n",
    "        # Aktualisiere die Lag-Features basierend auf der Vorhersage\n",
    "        X_next.loc[:, 'lag_1'] = y_next_pred  # Verschiebe die vorhergesagte Sales als lag_1\n",
    "        X_next.loc[:, 'lag_7'] = X_last['lag_1']  # Aktualisiere lag_7 mit den vorherigen lag_1 Werten\n",
    "        \n",
    "        # Aktualisiere andere Features\n",
    "        X_next.loc[:, 'day'] += 1  # Verschiebe den Tag\n",
    "        if X_next.loc[:, 'day'].values[0] > 31:  # Beispiel: Überlauf des Tages\n",
    "            X_next.loc[:, 'day'] = 1\n",
    "            X_next.loc[:, 'month'] += 1  # Verschiebe den Monat bei Tageswechsel\n",
    "        if X_next.loc[:, 'month'].values[0] > 12:  # Überlauf des Monats\n",
    "            X_next.loc[:, 'month'] = 1\n",
    "            X_next.loc[:, 'year'] += 1\n",
    "        \n",
    "        # Aktualisiere Wochenzahl\n",
    "        X_next.loc[:, 'week_of_year'] = (X_next['week_of_year'] % 52) + 1\n",
    "        \n",
    "        # Aktualisiere den Tag der Woche\n",
    "        X_next.loc[:, 'DayOfWeek'] = (X_next['DayOfWeek'] % 7) + 1\n",
    "        \n",
    "        # Nutze die Promo-Informationen aus dem Testdatensatz für den jeweiligen Tag\n",
    "        if day < len(test_data):  # Wenn der Testdatensatz Informationen für den Tag enthält\n",
    "            X_next.loc[:, 'Promo'] = test_data.iloc[day]['Promo']\n",
    "        else:\n",
    "            X_next.loc[:, 'Promo'] = 0  # Standardwert, falls keine Informationen vorhanden sind\n",
    "        \n",
    "        # Optional: Aktualisiere andere Features (Open, StateHoliday etc.) basierend auf Testdaten\n",
    "        if 'Open' in test_data.columns:\n",
    "            X_next.loc[:, 'Open'] = test_data.iloc[day]['Open']\n",
    "        if 'StateHoliday' in test_data.columns:\n",
    "            X_next.loc[:, 'StateHoliday'] = test_data.iloc[day]['StateHoliday']\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# TimeSeriesSplit für Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Überprüfung mit Cross-Validation\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "cv_rmspe_scores = []\n",
    "for train_idx, test_idx in tscv.split(X_train):\n",
    "    X_train_cv, X_test_cv = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    # Pipeline auf den Cross-Validation-Trainingsdaten fitten\n",
    "    pipeline.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # Vorhersage für den Testdatensatz\n",
    "    y_pred_cv = pipeline.predict(X_test_cv)\n",
    "    \n",
    "    # Berechne RMSPE für diesen Split\n",
    "    rmspe_score = rmspe(y_test_cv, y_pred_cv)\n",
    "    cv_rmspe_scores.append(rmspe_score)\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "mean_cv_rmspe = np.mean(cv_rmspe_scores)\n",
    "print(f\"Durchschnittliche RMSPE (Cross-Validation): {mean_cv_rmspe:.4f}\")\n",
    "\n",
    "# Nimm die letzten Daten als Startpunkt für die Vorhersage\n",
    "X_last = X_test.iloc[-1]\n",
    "\n",
    "# Vorhersage für die nächsten 7 Tage unter Verwendung von Promo-Informationen aus dem Testdatensatz\n",
    "num_days = 7\n",
    "test_data_next_days = X_test.iloc[:num_days]  # Extrahiere die Testdaten für die nächsten Tage\n",
    "\n",
    "# Vorhersagen für die nächsten Tage machen\n",
    "future_predictions = predict_multiple_days_with_updates(X_last, test_data_next_days, num_days)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(f\"Vorhersagen für die nächsten {num_days} Tage:\", future_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 estimator:\n",
    "Durchschnittliche RMSPE (Cross-Validation): 0.2424\n",
    "Vorhersagen für die nächsten 7 Tage: [9299.0, 9005.0, 8796.0, 0.0, 0.0, 8942.0, 8649.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bestimmen genauigkeit vorhersage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittliche RMSPE (Cross-Validation): 0.2126\n",
      "Vorhersagen für die nächsten 7 Tage: [9702.0, 9405.5, 8239.25, 0.0, 0.0, 10660.85, 10142.75]\n",
      "RMSPE der Vorhersagen für die nächsten 7 Tage: 0.6569\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# RMSPE Funktion definieren\n",
    "def rmspe(y_true, y_pred):\n",
    "    y_pred = np.array(y_pred)  # Umwandlung der Vorhersagen in ein Numpy-Array\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# RMSPE als Scorer definieren\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n",
    "\n",
    "# Laden des Datensatzes\n",
    "data_cleaned = \"../data/cleaned_train_alt.csv\"\n",
    "data = pd.read_csv(data_cleaned, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'lag_1', 'lag_7']\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "categorical_features_to_encode = ['Store', 'DayOfWeek', 'StoreType', 'StateHoliday', 'Assortment']\n",
    "\n",
    "# Preprocessing Pipeline für numerische und kategorische Features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features + already_encoded_features),\n",
    "        ('enc', 'passthrough', already_encoded_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)\n",
    "    ])\n",
    "\n",
    "# Modell für RandomForest erstellen\n",
    "model = RandomForestRegressor(n_estimators=20, random_state=42)\n",
    "\n",
    "# Pipeline erstellen\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Funktion zur Vorhersage mehrerer Tage mit Feature-Update\n",
    "def predict_multiple_days_with_updates(X_last, test_data, num_days):\n",
    "    predictions = []\n",
    "    X_next = X_last.copy()\n",
    "\n",
    "    # Wandle X_next in ein DataFrame um, falls es keine DataFrame ist\n",
    "    X_next = pd.DataFrame([X_next])\n",
    "\n",
    "    for day in range(num_days):\n",
    "        # Vorhersage des nächsten Tages\n",
    "        y_next_pred = pipeline.predict(X_next)[0]\n",
    "        predictions.append(y_next_pred)\n",
    "        \n",
    "        # Aktualisiere die Lag-Features basierend auf der Vorhersage\n",
    "        X_next.loc[:, 'lag_1'] = y_next_pred  # Verschiebe die vorhergesagte Sales als lag_1\n",
    "        X_next.loc[:, 'lag_7'] = X_last['lag_1']  # Aktualisiere lag_7 mit den vorherigen lag_1 Werten\n",
    "        \n",
    "        # Aktualisiere andere Features\n",
    "        X_next.loc[:, 'day'] += 1  # Verschiebe den Tag\n",
    "        if X_next.loc[:, 'day'].values[0] > 31:  # Beispiel: Überlauf des Tages\n",
    "            X_next.loc[:, 'day'] = 1\n",
    "            X_next.loc[:, 'month'] += 1  # Verschiebe den Monat bei Tageswechsel\n",
    "        if X_next.loc[:, 'month'].values[0] > 12:  # Überlauf des Monats\n",
    "            X_next.loc[:, 'month'] = 1\n",
    "            X_next.loc[:, 'year'] += 1\n",
    "        \n",
    "        # Aktualisiere Wochenzahl\n",
    "        X_next.loc[:, 'week_of_year'] = (X_next['week_of_year'] % 52) + 1\n",
    "        \n",
    "        # Aktualisiere den Tag der Woche\n",
    "        X_next.loc[:, 'DayOfWeek'] = (X_next['DayOfWeek'] % 7) + 1\n",
    "        \n",
    "        # Nutze die Promo-Informationen aus dem Testdatensatz für den jeweiligen Tag\n",
    "        if day < len(test_data):  # Wenn der Testdatensatz Informationen für den Tag enthält\n",
    "            X_next.loc[:, 'Promo'] = test_data.iloc[day]['Promo']\n",
    "        else:\n",
    "            X_next.loc[:, 'Promo'] = 0  # Standardwert, falls keine Informationen vorhanden sind\n",
    "        \n",
    "        # Optional: Aktualisiere andere Features (Open, StateHoliday etc.) basierend auf Testdaten\n",
    "        if 'Open' in test_data.columns:\n",
    "            X_next.loc[:, 'Open'] = test_data.iloc[day]['Open']\n",
    "        if 'StateHoliday' in test_data.columns:\n",
    "            X_next.loc[:, 'StateHoliday'] = test_data.iloc[day]['StateHoliday']\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# TimeSeriesSplit für Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Überprüfung mit Cross-Validation\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "cv_rmspe_scores = []\n",
    "for train_idx, test_idx in tscv.split(X_train):\n",
    "    X_train_cv, X_test_cv = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    # Pipeline auf den Cross-Validation-Trainingsdaten fitten\n",
    "    pipeline.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # Vorhersage für den Testdatensatz\n",
    "    y_pred_cv = pipeline.predict(X_test_cv)\n",
    "    \n",
    "    # Berechne RMSPE für diesen Split\n",
    "    rmspe_score = rmspe(y_test_cv.values, y_pred_cv)\n",
    "    cv_rmspe_scores.append(rmspe_score)\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "mean_cv_rmspe = np.mean(cv_rmspe_scores)\n",
    "print(f\"Durchschnittliche RMSPE (Cross-Validation): {mean_cv_rmspe:.4f}\")\n",
    "\n",
    "# Nimm die letzten Daten als Startpunkt für die Vorhersage\n",
    "X_last = X_test.iloc[-1]\n",
    "\n",
    "# Vorhersage für die nächsten 7 Tage unter Verwendung von Promo-Informationen aus dem Testdatensatz\n",
    "num_days = 7\n",
    "test_data_next_days = X_test.iloc[:num_days]  # Extrahiere die Testdaten für die nächsten Tage\n",
    "\n",
    "# Vorhersagen für die nächsten Tage machen\n",
    "future_predictions = predict_multiple_days_with_updates(X_last, test_data_next_days, num_days)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(f\"Vorhersagen für die nächsten {num_days} Tage:\", future_predictions)\n",
    "\n",
    "# Tatsächliche Verkaufszahlen für die nächsten 7 Tage aus dem Testdatensatz extrahieren\n",
    "actual_sales_next_days = y_test.iloc[:num_days].values\n",
    "\n",
    "# Berechnung der RMSPE für die Vorhersagen\n",
    "prediction_rmspe = rmspe(actual_sales_next_days, future_predictions)\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "print(f\"RMSPE der Vorhersagen für die nächsten {num_days} Tage: {prediction_rmspe:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durchschnittliche RMSPE (Cross-Validation): 0.2126\n",
    "Vorhersagen für die nächsten 7 Tage: [9702.0, 9405.5, 8239.25, 0.0, 0.0, 10660.85, 10142.75]\n",
    "RMSPE der Vorhersagen für die nächsten 7 Tage: 0.6569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittliche RMSPE (Cross-Validation): 0.2386\n",
      "Vorhersagen für die nächsten 60 Tage: [6868.0, 6235.0, 5694.0, 0.0, 0.0, 9615.0, 8180.0, 6480.0, 6328.0, 5470.0, 0.0, 4090.0, 3776.0, 3756.0, 3973.0, 3476.0, 3169.0, 0.0, 9615.0, 10744.0, 10041.0, 8735.0, 9165.0, 8373.0, 0.0, 15301.0, 25107.0, 16837.0, 18127.0, 16058.0, 16077.0, 0.0, 8324.0, 8328.0, 8328.0, 6355.0, 6594.0, 6588.0, 0.0, 4090.0, 3646.0, 3309.0, 2723.0, 3333.0, 2685.0, 0.0, 9615.0, 10311.0, 10216.0, 8735.0, 9165.0, 8373.0, 0.0, 4090.0, 3646.0, 3309.0, 2930.0, 3848.0, 4086.0, 0.0]\n",
      "RMSPE der Vorhersagen für die nächsten 60 Tage: 0.9235\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# RMSPE Funktion definieren\n",
    "def rmspe(y_true, y_pred):\n",
    "    y_pred = np.array(y_pred)  # Umwandlung der Vorhersagen in ein Numpy-Array\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# RMSPE als Scorer definieren\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n",
    "\n",
    "# Laden des Datensatzes\n",
    "data_cleaned = \"../data/cleaned_train_alt.csv\"\n",
    "data = pd.read_csv(data_cleaned, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'lag_1', 'lag_7']\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "categorical_features_to_encode = ['Store', 'DayOfWeek', 'StoreType', 'StateHoliday', 'Assortment']\n",
    "\n",
    "# Preprocessing Pipeline für numerische und kategorische Features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('enc', 'passthrough', already_encoded_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)\n",
    "    ])\n",
    "\n",
    "# Modell für RandomForest erstellen\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Pipeline erstellen\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "#Funktion zur vorhersage der nächsten x Tage\n",
    "def predict_multiple_days_with_updates(X_last, test_data, num_days):\n",
    "    predictions = []\n",
    "    X_next = X_last.copy()\n",
    "    X_next = pd.DataFrame([X_next])  # In DataFrame umwandeln\n",
    "    last_lags = list(X_last[['lag_1']].values.flatten())  # Initialisiere letzte Lags\n",
    "\n",
    "    for day in range(num_days):\n",
    "        # Preprocess die Daten vor der Vorhersage\n",
    "        X_next_preprocessed = pipeline.named_steps['preprocessor'].transform(X_next)\n",
    "        \n",
    "        # Vorhersage des nächsten Tages\n",
    "        y_next_pred = pipeline.named_steps['model'].predict(X_next_preprocessed)[0]\n",
    "        predictions.append(y_next_pred)\n",
    "\n",
    "        # Aktualisiere die Lag-Features basierend auf der Vorhersage\n",
    "        last_lags.append(y_next_pred)\n",
    "        last_lags.pop(0)  # Aktualisiere Lag-Werte\n",
    "\n",
    "        X_next.loc[:, 'lag_1'] = y_next_pred\n",
    "        X_next.loc[:, 'lag_7'] = last_lags[0]\n",
    "\n",
    "        # Aktualisiere andere Features (Tag, Monat, Woche)\n",
    "        X_next.loc[:, 'day'] += 1\n",
    "        if X_next.loc[:, 'day'].values[0] > 31:\n",
    "            X_next.loc[:, 'day'] = 1\n",
    "            X_next.loc[:, 'month'] += 1\n",
    "        if X_next.loc[:, 'month'].values[0] > 12:\n",
    "            X_next.loc[:, 'month'] = 1\n",
    "            X_next.loc[:, 'year'] += 1\n",
    "\n",
    "        X_next.loc[:, 'week_of_year'] = (X_next['week_of_year'] % 52) + 1\n",
    "        X_next.loc[:, 'DayOfWeek'] = (X_next['DayOfWeek'] % 7) + 1\n",
    "\n",
    "        # Promo- und andere Features aus Testdaten übernehmen\n",
    "        if day < len(test_data):\n",
    "            X_next.loc[:, 'Promo'] = test_data.iloc[day]['Promo']\n",
    "            X_next.loc[:, 'Open'] = test_data.iloc[day]['Open']\n",
    "            X_next.loc[:, 'StateHoliday'] = test_data.iloc[day]['StateHoliday']\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# TimeSeriesSplit für Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Überprüfung mit Cross-Validation\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "cv_rmspe_scores = []\n",
    "for train_idx, test_idx in tscv.split(X_train):\n",
    "    X_train_cv, X_test_cv = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Pipeline auf den Cross-Validation-Trainingsdaten fitten\n",
    "    pipeline.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    # Vorhersage für den Testdatensatz\n",
    "    y_pred_cv = pipeline.predict(X_test_cv)\n",
    "\n",
    "    # Berechne RMSPE für diesen Split\n",
    "    rmspe_score = rmspe(y_test_cv.values, y_pred_cv)\n",
    "    cv_rmspe_scores.append(rmspe_score)\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "mean_cv_rmspe = np.mean(cv_rmspe_scores)\n",
    "print(f\"Durchschnittliche RMSPE (Cross-Validation): {mean_cv_rmspe:.4f}\")\n",
    "\n",
    "# Nimm die letzten Daten als Startpunkt für die Vorhersage\n",
    "X_last = X_test.iloc[-60]\n",
    "\n",
    "# Vorhersage für die nächsten 7 Tage unter Verwendung von Promo-Informationen aus dem Testdatensatz\n",
    "num_days = 60\n",
    "test_data_next_days = X_test.iloc[:num_days]  # Extrahiere die Testdaten für die nächsten Tage\n",
    "\n",
    "# Vorhersagen für die nächsten Tage machen\n",
    "future_predictions = predict_multiple_days_with_updates(X_last, test_data_next_days, num_days)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(f\"Vorhersagen für die nächsten {num_days} Tage:\", future_predictions)\n",
    "\n",
    "# Tatsächliche Verkaufszahlen für die nächsten 7 Tage aus dem Testdatensatz extrahieren\n",
    "actual_sales_next_days = y_test.iloc[:num_days].values\n",
    "\n",
    "# Berechnung der RMSPE für die Vorhersagen\n",
    "prediction_rmspe = rmspe(actual_sales_next_days, future_predictions)\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "print(f\"RMSPE der Vorhersagen für die nächsten {num_days} Tage: {prediction_rmspe:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Baum, 7 Tage:\n",
    "Durchschnittliche RMSPE (Cross-Validation): 0.2386\n",
    "Vorhersagen für die nächsten 7 Tage: [6868.0, 6235.0, 5694.0, 0.0, 0.0, 9615.0, 8180.0]\n",
    "RMSPE der Vorhersagen für die nächsten 7 Tage: 0.4642\n",
    "\n",
    "1 Baum, 60 Tage:\n",
    "Durchschnittliche RMSPE (Cross-Validation): 0.2386\n",
    "Vorhersagen für die nächsten 60 Tage: [6868.0, 6235.0, 5694.0, 0.0, 0.0, 9615.0, 8180.0, 6480.0, 6328.0, 5470.0, 0.0, 4090.0, 3776.0, 3756.0, 3973.0, 3476.0, 3169.0, 0.0, 9615.0, 10744.0, 10041.0, 8735.0, 9165.0, 8373.0, 0.0, 15301.0, 25107.0, 16837.0, 18127.0, 16058.0, 16077.0, 0.0, 8324.0, 8328.0, 8328.0, 6355.0, 6594.0, 6588.0, 0.0, 4090.0, 3646.0, 3309.0, 2723.0, 3333.0, 2685.0, 0.0, 9615.0, 10311.0, 10216.0, 8735.0, 9165.0, 8373.0, 0.0, 4090.0, 3646.0, 3309.0, 2930.0, 3848.0, 4086.0, 0.0]\n",
    "RMSPE der Vorhersagen für die nächsten 60 Tage: 0.9235\n",
    "\n",
    "40 Bäume, 60 Tage: \n",
    "Durchschnittliche RMSPE (Cross-Validation): 0.2112\n",
    "Vorhersagen für die nächsten 60 Tage: [7006.95, 6038.9, 5713.375, 0.0, 0.0, 10342.425, 11745.55, 9687.325, 8993.9, 7979.475, 0.0, 11497.0, 14109.975, 13406.45, 11244.675, 9955.425, 9238.6, 0.0, 9574.125, 10272.075, 9887.45, 8986.45, 8635.05, 8113.35, 0.0, 11631.925, 14490.2, 15139.7, 15196.65, 10676.875, 9921.975, 0.0, 7064.925, 6889.55, 11720.025, 9834.7, 9020.85, 7961.35, 0.0, 10148.875, 9110.1, 7964.1, 6368.0, 5449.375, 5042.275, 0.0, 8972.25, 9663.475, 10388.15, 9497.2, 8774.325, 7876.825, 0.0, 8724.725, 8219.7, 7496.45, 6704.05, 7345.7, 7603.85, 0.0]\n",
    "RMSPE der Vorhersagen für die nächsten 60 Tage: 0.8358"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Überprüfen wie Werte in X_test aussehen und wieviele Einträge vorhanden sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test\n",
      "203442\n",
      "X_last\n",
      "Store                      1115\n",
      "DayOfWeek                     2\n",
      "Date                 2015-06-02\n",
      "Open                          1\n",
      "Promo                         1\n",
      "StateHoliday                  0\n",
      "year                       2015\n",
      "month                         6\n",
      "day                           2\n",
      "week_of_year                 23\n",
      "day_of_week                   1\n",
      "is_weekend                    0\n",
      "is_holiday                    0\n",
      "is_school_holiday             0\n",
      "StoreType                     d\n",
      "Assortment                    c\n",
      "promo2                        1\n",
      "lag_1                    8409.0\n",
      "lag_7                    6726.0\n",
      "Name: 1017149, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# RMSPE Funktion definieren\n",
    "def rmspe(y_true, y_pred):\n",
    "    y_pred = np.array(y_pred)  # Umwandlung der Vorhersagen in ein Numpy-Array\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# RMSPE als Scorer definieren\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n",
    "\n",
    "# Laden des Datensatzes\n",
    "data_cleaned = \"../data/cleaned_train_alt.csv\"\n",
    "data = pd.read_csv(data_cleaned, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'lag_1', 'lag_7']\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "categorical_features_to_encode = ['Store', 'DayOfWeek', 'StoreType', 'StateHoliday', 'Assortment']\n",
    "\n",
    "\n",
    "# Überprüfung mit Cross-Validation\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Nimm die letzten Daten als Startpunkt für die Vorhersage\n",
    "X_last = X_test.iloc[0]\n",
    "\n",
    "print(\"X_test\")\n",
    "print(len(X_test))\n",
    "print(\"X_last\")\n",
    "print(X_last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
