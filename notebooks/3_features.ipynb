{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstellen neuer Features\n",
    "\n",
    "Zum Erstellen der neuen Features werden zunächst die Verkaufsdaten (train.csv) und die Geschäftsdaten (store.csv) geladen und anschließend eine umfangreiche Datenvorverarbeitung und Feature-Engineering durchgeführt. Nachdem die Daten geladen und in ein Pandas DataFrame eingelesen wurden, wird die `Date`-Spalte in ein Datetime-Format konvertiert und verschiedene zeitbezogene Features wie Jahr, Monat, Tag, Wochentag und Kalenderwoche erstellt. Wochenenden, Feiertage und Schulferien werden als binäre Features kodiert, um diese speziellen Tage zu identifizieren. Anschließend werden die Verkaufsdaten (train) mit den Geschäftsdaten (`Store`) anhand der Store-ID zusammengeführt, um zusätzliche geschäftsspezifische Informationen hinzuzufügen. Lag Features, die die Verkaufszahlen der vorhergehenden Tage und Wochen darstellen, werden erstellt. Dabei werden die Verkaufszahlen eines Tages, einer Woche und eines Monats vorher berücksichtigt. Zusätzlich werden Rolling Features, die den gleitenden Durchschnitt und die Standardabweichung der Verkaufszahlen über bestimmte Zeiträume darstellen, erstellt. Store-spezifische Features wie die Dauer, seitdem ein Wettbewerber geöffnet hat (`competition_open_since`), und die Dauer, seitdem eine Promotion läuft (`promo2_since`), werden berechnet. Promotionsintervalle werden in binäre Features (`is_promo_month`) umgewandelt, um anzugeben, ob der aktuelle Monat Teil eines Promotionsintervalls ist. Weiterhin werden Dummy-Variablen für kategorische Features wie `StoreType`, `Assortment` und `StateHoliday` erstellt, um diese in das Modell zu integrieren. Nicht-numerische Spalten werden entfernt, um sicherzustellen, dass nur numerische Daten für die Modellierung verwendet werden. Fehlende Werte in den Daten werden mit Null aufgefüllt. Schließlich wird die Korrelation zwischen den neu erstellten Features und den vorhandenen Spalten berechnet und in einer Korrelationsmatrix dargestellt. Diese Matrix zeigt die Korrelation der neuen Features (`lag_1`, `lag_7`, `lag_30`, `rolling_mean_7`, `rolling_mean_30`, `rolling_std_7`, `rolling_std_30`, `competition_open_since`, `promo2_since`, `is_promo_month`) mit den bestehenden Features (`Sales`, `Customers`, `Open`, `Promo`, `Promo2`, `SchoolHoliday`, `CompetitionDistance`) an, um deren Beziehung und potenziellen Einfluss auf die Verkaufszahlen zu analysieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_store = \"../data/store.csv\"\n",
    "file_train = \"../data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.read_csv(file_store, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)\n",
    "train = pd.read_csv(file_train, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Sales  Customers      Open     Promo    Promo2  \\\n",
      "lag_1                   0.276397   0.260692 -0.208566  0.294136 -0.091021   \n",
      "lag_7                   0.662853   0.670439  0.526126  0.026569 -0.090166   \n",
      "lag_30                  0.191832   0.216545 -0.094959 -0.098374 -0.087246   \n",
      "rolling_mean_7          0.023603  -0.009056 -0.274540  0.372539 -0.017115   \n",
      "rolling_mean_30        -0.012717  -0.052700 -0.285845  0.383969 -0.002199   \n",
      "rolling_std_7           0.070373   0.081538 -0.158349  0.218808 -0.018167   \n",
      "rolling_std_30          0.017435   0.002728 -0.195727  0.255184 -0.005841   \n",
      "competition_open_since -0.004141  -0.004701 -0.002709  0.001811  0.014907   \n",
      "promo2_since           -0.042132  -0.107720 -0.006164  0.005354  0.633306   \n",
      "is_promo_month         -0.044955  -0.069586  0.000916  0.003559  0.454996   \n",
      "\n",
      "                        SchoolHoliday  CompetitionDistance  \n",
      "lag_1                        0.033883            -0.018596  \n",
      "lag_7                        0.088015            -0.018304  \n",
      "lag_30                      -0.089403            -0.016816  \n",
      "rolling_mean_7               0.054170            -0.007355  \n",
      "rolling_mean_30              0.056127            -0.004376  \n",
      "rolling_std_7                0.040912            -0.029889  \n",
      "rolling_std_30               0.038144            -0.016770  \n",
      "competition_open_since      -0.001993            -0.017070  \n",
      "promo2_since                -0.005633            -0.045001  \n",
      "is_promo_month               0.016409            -0.062970  \n"
     ]
    }
   ],
   "source": [
    "# convert date and create temporal features\n",
    "train['Date'] = pd.to_datetime(train['Date'])\n",
    "train['year'] = train['Date'].dt.year\n",
    "train['month'] = train['Date'].dt.month\n",
    "train['day'] = train['Date'].dt.day\n",
    "#train['day_of_week'] = train['Date'].dt.dayofweek\n",
    "train['week_of_year'] = train['Date'].dt.isocalendar().week\n",
    "\n",
    "# Weekends, public holidays and school vacations are coded as binary features.\n",
    "#train['is_weekend'] = train['day_of_week'].isin([5, 6]).astype(int)\n",
    "#train['is_holiday'] = (train['StateHoliday'] != '0').astype(int)\n",
    "#train['is_school_holiday'] = train['SchoolHoliday']\n",
    "\n",
    "# Merge train dataset with store dataset using the store ID to add store-specific information\n",
    "data_info = pd.merge(train, store, on='Store')\n",
    "\n",
    "# Create lag features (sales of the previous days/weeks)\n",
    "data_info['lag_1'] = data_info.groupby('Store')['Sales'].shift(1)\n",
    "data_info['lag_7'] = data_info.groupby('Store')['Sales'].shift(7)\n",
    "data_info['lag_30'] = data_info.groupby('Store')['Sales'].shift(30)\n",
    "\n",
    "# Create rolling features (moving average and standard deviation)\n",
    "data_info['rolling_mean_7'] = data_info.groupby('Store')['Sales'].shift(1).rolling(window=7).mean()\n",
    "data_info['rolling_mean_30'] = data_info.groupby('Store')['Sales'].shift(1).rolling(window=30).mean()\n",
    "data_info['rolling_std_7'] = data_info.groupby('Store')['Sales'].shift(1).rolling(window=7).std()\n",
    "data_info['rolling_std_30'] = data_info.groupby('Store')['Sales'].shift(1).rolling(window=30).std()\n",
    "\n",
    "# Create store-specific features (= duration since a competitor has opened)\n",
    "data_info['competition_open_since'] = (\n",
    "    (data_info['year'] - data_info['CompetitionOpenSinceYear']) * 12 +\n",
    "    (data_info['month'] - data_info['CompetitionOpenSinceMonth'])\n",
    ")\n",
    "\n",
    "# Create promotion features (= duration since a promotion has been running)\n",
    "data_info['promo2_since'] = (\n",
    "    (data_info['year'] - data_info['Promo2SinceYear']) * 52 +\n",
    "    (data_info['week_of_year'] - data_info['Promo2SinceWeek'])\n",
    ")\n",
    "\n",
    "\n",
    "promo_intervals = {'Jan,Apr,Jul,Oct': [1, 4, 7, 10],\n",
    "                   'Feb,May,Aug,Nov': [2, 5, 8, 11],\n",
    "                   'Mar,Jun,Sept,Dec': [3, 6, 9, 12]}\n",
    "# Promotion intervals are converted into binary features (is_promo_month), see Hinweis                 \n",
    "data_info['is_promo_month'] = data_info.apply(lambda row: 1 if row['month'] in promo_intervals.get(row['PromoInterval'], []) else 0, axis=1)\n",
    "\n",
    "# Create dummy variables for categorical features\n",
    "data_info = pd.get_dummies(data_info, columns=['StoreType', 'Assortment', 'StateHoliday'], drop_first=True)\n",
    "\n",
    "# Remove non-numeric columns\n",
    "non_numeric_columns = data_info.select_dtypes(include=['object']).columns\n",
    "data_info = data_info.drop(columns=non_numeric_columns)\n",
    "\n",
    "# Fill in missing values\n",
    "data_info.fillna(0, inplace=True)\n",
    "\n",
    "# Calculate correlation\n",
    "correlation_matrix = data_info.corr()\n",
    "\n",
    "# Show correlation of the new features with the existing columns\n",
    "new_features = ['lag_1', 'lag_7', 'lag_30', 'rolling_mean_7', 'rolling_mean_30', 'rolling_std_7', 'rolling_std_30', 'competition_open_since', 'promo2_since', 'is_promo_month']\n",
    "existing_features = ['Sales', 'Customers', 'Open', 'Promo', 'Promo2', 'SchoolHoliday', 'CompetitionDistance']\n",
    "\n",
    "correlation_new_vs_existing = correlation_matrix.loc[new_features, existing_features]\n",
    "\n",
    "print(correlation_new_vs_existing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              0.0\n",
       "1              0.0\n",
       "2              0.0\n",
       "3              0.0\n",
       "4              0.0\n",
       "            ...   \n",
       "1017204     5097.0\n",
       "1017205    10797.0\n",
       "1017206     6218.0\n",
       "1017207    20642.0\n",
       "1017208     3697.0\n",
       "Name: lag_1, Length: 1017209, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_info['lag_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hinweis:\n",
    "1. Nicht-numerische Spalten entfernen: Spalten, die Zeichenketten enthalten, werden vor der Berechnung der Korrelationen entfernt.\n",
    "2. Fehlende Werte auffüllen: Fehlende Werte werden mit 0 aufgefüllt, um sicherzustellen, dass keine NaN-Werte die Korrelationsberechnung beeinträchtigen.\n",
    "\n",
    "Dieser Ansatz stellt sicher, dass nur numerische Daten in die Berechnung der Korrelationen einfließen und vermeidet den ValueError."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse der neu erstellten Features\n",
    "\n",
    "Um zu beurteilen, ob die neu erstellten Features für die Vorhersage der Verkäufe geeignet sind, eignet sich die Korrelationsmatrix. Ein neues Feature ist gut geeignet, wenn es eine hohe positive oder negative Korrelation mit den Verkäufen (`Sales`) aufweist. Eine hohe positive Korrelation bedeutet, dass das Feature einen starken positiven Zusammenhang mit den Verkaufszahlen hat, was es in der Regel nützlich für Vorhersagemodelle macht. Eine hohe negative Korrelation deutet ebenfalls auf eine starke Beziehung hin, jedoch in die entgegengesetzte Richtung, was ebenfalls hilfreich sein kann. Zusätzlich sind hohe Korrelationen mit anderen relevanten Features wie `Promo` nützlich, da sie auf mögliche indirekte Einflüsse auf die Verkäufe hinweisen können. Anhand der erstellten Korrelationsmatrix können neuen Features wie folgt bewertet werden:\n",
    "\n",
    "- Das Feature `lag_1` zeigt eine mäßig positive Korrelation mit `Sales` (0.276397), was es zu einem mäßigen Prädiktor für Verkäufe macht. Für `SchoolHoliday` (0.033883) und `CompetitionDistance` (-0.018596) ist die Korrelation jedoch sehr schwach. Insgesamt kann `lag_1` nützlich sein, insbesondere für kurzfristige Vorhersagen.\n",
    "\n",
    "- Das Feature `lag_7` weist eine hohe positive Korrelation mit `Sales` (0.662853) auf, was es zu einem starken Prädiktor für diese Variable macht. Die Korrelation mit `SchoolHoliday` (0.088015) und `CompetitionDistance` (-0.018304) ist jedoch sehr schwach. `lag_7` sollte dennoch aufgrund der hohen Korrelation mit `Sales` im Modell verwendet werden.\n",
    "\n",
    "- Das Feature `lag_30` zeigt eine schwache positive Korrelation mit `Sales` (0.191832), sowie sehr schwache negative Korrelationen mit `SchoolHoliday` (-0.089403) und `CompetitionDistance` (-0.016816). Aufgrund der schwachen Korrelationen ist `lag_30` möglicherweise weniger nützlich.\n",
    "\n",
    "- Die `rolling_mean_7`- und `rolling_mean_30`-Features zeigen insgesamt sehr schwache Korrelationen mit `Sales`, `Customers`, `SchoolHoliday` und `CompetitionDistance`, was darauf hinweist, dass sie schwache Prädiktoren sind.\n",
    "\n",
    "- Die `rolling_std_7`- und `rolling_std_30`-Features zeigen ebenfalls sehr schwache Korrelationen mit den betrachteten Variablen, was ihre Nützlichkeit als Prädiktoren weiter einschränkt.\n",
    "\n",
    "- Das Feature `competition_open_since` weist durchweg sehr schwache negative Korrelationen mit `Sales`, `SchoolHoliday` und `CompetitionDistance` auf, was darauf hindeutet, dass es ein sehr schwacher Prädiktor ist.\n",
    "\n",
    "- Das Feature `promo2_since` zeigt ebenfalls sehr schwache negative Korrelationen mit allen betrachteten Variablen, was es zu einem weiteren schwachen Prädiktor macht.\n",
    "\n",
    "- Das Feature `is_promo_month` zeigt sehr schwache negative Korrelationen mit `Sales`, sowie eine sehr schwache positive Korrelation mit `SchoolHoliday`, was seine Nützlichkeit als Prädiktor weiter einschränkt.\n",
    "\n",
    "Auf Grundlage der Korrelationsmatrix sind insbesondere die Features `lag_7` und `lag_1` nützlich, da sie starke bzw. mäßige positive Korrelationen mit `Sales` aufweisen. Die anderen neuen Features zeigen sehr schwache Korrelationen mit `Sales` und anderen wichtigen Spalten, was darauf hinweist, dass sie weniger nützlich für die Vorhersage sind. Es kann jedoch sinnvoll sein, einige dieser Features weiterhin zu berücksichtigen und ihre Wirkung in einem tatsächlichen Modell zu testen, da die Korrelation allein nicht immer die volle Aussagekraft eines Features zeigt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstellen des Features Promo\n",
    "\n",
    "Ein Problem in den vorliegenden Daten ist, dass die Spalten \"Promo2SinceWeek\", \"Promo2SinceYear\" und \"PromoInterval\" NaN-Werte enthalten, sollte ein Store nicht an einer Promotion-Aktion teilnehmen. Da jedoch nicht jedes Modell mit NaN-Werten umgehen kann, müssen diese mit sinnvollen Werten ersetzt werden. Um dieses Problem zu lösen, wird eine neue Spalte in der Trainingsdatei erstellt, die die Werte Null oder Eins enthält. Null bedeutet, dass an diesem Tag in dem Store keine Promotion stattfindet, während Eins anzeigt, dass eine Promotion stattfindet. Um dies zu erreichen, werden die Spalten `Promo2`, `Promo2SinceWeek`, `Promo2SinceYear` und `PromoInterval` aus der `store`-Datei zusammengeführt und in die Trainingsdatei übernommen. Hierfür wird mit Hilfe der `Promo2`-Spalte überprüft ob ein Store an einer Aktion teilnimmt. Sollte dies der Fall sein, das heißt eine Eins ist eingetragen, so kann mit Hilfe der Spalten `Promo2SinceWeek`, `Promo2SinceYear` und `PromoInterval` jeder Tag berechnet werden an dem der Store an der Aktion teilgenommen hat. Für diese Tage wird in der `promo`-Spalte der Trainingsdatei eine Eins eingetragen. Für alle anderen Tage, das heißt Tage an denen keine Promotion in Stores stattfindet, wird eine Null eingetragen. Somit sind keine NaN-Werte mehr vorhanden, da diese mit sinnvollen Werten ersetzt wurden. Für jeden Tag wird daher, basierend auf den Informationen aus den `store`-Daten, berechnet, ob der Store an einer Promotion teilnimmt oder nicht. Die beschriebene Vorgehensweise ist möglich, da die `Promo2`-Spalte immer Werte enthält (Null oder Eins). Aus diesen Werten kann abgeleitet werden, dass NaN-Werte in den anderen Spalten entstehen, da der Store nicht an der Aktion teilnimmt und somit keine Werte in diese Spalten eingetragen werden können. Für die NaN-Zeilen können daher in der neu erstellten Promotionsspalte der Trainingsdatei eine 0 eingetragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/z15ws_pd5x5_76bbfygfn4ch0000gn/T/ipykernel_57479/926152441.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Promo2SinceWeek'].fillna(0, inplace=True)\n",
      "/var/folders/7l/z15ws_pd5x5_76bbfygfn4ch0000gn/T/ipykernel_57479/926152441.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Promo2SinceYear'].fillna(0, inplace=True)\n",
      "/var/folders/7l/z15ws_pd5x5_76bbfygfn4ch0000gn/T/ipykernel_57479/926152441.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['PromoInterval'].fillna('', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store  DayOfWeek       Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
      "0      1          5 2015-07-31   5263        555     1      1            0   \n",
      "1      2          5 2015-07-31   6064        625     1      1            0   \n",
      "2      3          5 2015-07-31   8314        821     1      1            0   \n",
      "3      4          5 2015-07-31  13995       1498     1      1            0   \n",
      "4      5          5 2015-07-31   4822        559     1      1            0   \n",
      "\n",
      "   SchoolHoliday  year  ...  day_of_week  is_weekend  is_holiday  \\\n",
      "0              1  2015  ...            4           0           0   \n",
      "1              1  2015  ...            4           0           0   \n",
      "2              1  2015  ...            4           0           0   \n",
      "3              1  2015  ...            4           0           0   \n",
      "4              1  2015  ...            4           0           0   \n",
      "\n",
      "   is_school_holiday  StoreType  Assortment  CompetitionDistance  \\\n",
      "0                  1          c           a               1270.0   \n",
      "1                  1          a           a                570.0   \n",
      "2                  1          a           a              14130.0   \n",
      "3                  1          c           c                620.0   \n",
      "4                  1          a           a              29910.0   \n",
      "\n",
      "  CompetitionOpenSinceMonth CompetitionOpenSinceYear  promo2  \n",
      "0                       9.0                   2008.0       0  \n",
      "1                      11.0                   2007.0       1  \n",
      "2                      12.0                   2006.0       1  \n",
      "3                       9.0                   2009.0       0  \n",
      "4                       4.0                   2015.0       0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert date and create temporal features\n",
    "train['Date'] = pd.to_datetime(train['Date'])\n",
    "train['year'] = train['Date'].dt.year\n",
    "train['month'] = train['Date'].dt.month\n",
    "train['day'] = train['Date'].dt.day\n",
    "train['day_of_week'] = train['Date'].dt.dayofweek\n",
    "train['week_of_year'] = train['Date'].dt.isocalendar().week\n",
    "\n",
    "# Encode weekends, public holidays and school vacations as binary features\n",
    "train['is_weekend'] = train['day_of_week'].isin([5, 6]).astype(int)\n",
    "train['is_holiday'] = (train['StateHoliday'] != '0').astype(int)\n",
    "train['is_school_holiday'] = train['SchoolHoliday']\n",
    "\n",
    "# Merge train data record with store data record using the store ID\n",
    "data = pd.merge(train, store, on='Store')\n",
    "\n",
    "# Fill NaN values in the promotion columns with 0\n",
    "data['Promo2SinceWeek'].fillna(0, inplace=True)\n",
    "data['Promo2SinceYear'].fillna(0, inplace=True)\n",
    "data['PromoInterval'].fillna('', inplace=True)\n",
    "\n",
    "# Create promotion column\n",
    "def is_promo(row):\n",
    "    if row['Promo2'] == 0:\n",
    "        return 0\n",
    "    if row['Promo2'] == 1:\n",
    "        promo_start_year = int(row['Promo2SinceYear'])\n",
    "        promo_start_week = int(row['Promo2SinceWeek'])\n",
    "        current_year = int(row['year'])\n",
    "        current_week = int(row['week_of_year'])\n",
    "        \n",
    "        # Calculation of whether the current date is in a promotion interval\n",
    "        if current_year > promo_start_year or (current_year == promo_start_year and current_week >= promo_start_week):\n",
    "            promo_intervals = {\n",
    "                'Jan,Apr,Jul,Oct': [1, 4, 7, 10],\n",
    "                'Feb,May,Aug,Nov': [2, 5, 8, 11],\n",
    "                'Mar,Jun,Sept,Dec': [3, 6, 9, 12]\n",
    "            }\n",
    "            intervals = promo_intervals.get(row['PromoInterval'], [])\n",
    "            if row['month'] in intervals:\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "data['promo2'] = data.apply(is_promo, axis=1)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "data.drop(columns=['Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval'], inplace=True)\n",
    "\n",
    "# Show result\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auswahl vorhandener Merkmale\n",
    "\n",
    "Die Auswahl weiterer Features für das Vorhersagemodell basiert auf ihrer logischen Relevanz und der Analyse ihrer Korrelation mit den Verkaufszahlen. \n",
    "\n",
    "- Der Wochentag (`DayOfWeek`) hat oft einen erheblichen Einfluss auf die Verkäufe, da die Kaufgewohnheiten der Kunden je nach Wochentag variieren können. Beispielsweise gibt es mehr Einkäufe an Wochenenden. Daher wird der Wochentag in Liste der verwendbaren Merkmale aufgenommen. \n",
    "\n",
    "- Das Merkmal `Customers` (Kundenanzahl) hingegen ist weniger geeignet. Diese Entscheidung basiert auf der Abwägung der Auswirkungen auf die Modellgenauigkeit und die Komplexität des Vorhersageprozesses. Die Einbeziehung dieses Features würde bedeuten, dass auch die Anzahl der Kunden für zukünftige Zeitpunkte vorhersagt werden müsste. Dies fügt eine zusätzliche Schicht von Komplexität hinzu, da nun zwei miteinander verknüpfte Vorhersagen getroffen werden müssten: die Anzahl der Kunden und darauf basierend die Verkaufszahlen. Die Vorhersage der Kundenanzahl würde zusätzliche Modelle oder Algorithmen erfordern, die ebenfalls eine gewisse Fehlerquote aufweisen. Diese Fehler würden sich in der Verkaufsprognose widerspiegeln und könnten die Genauigkeit des Verkaufsprognosemodells verringern. Durch den Ausschluss des `Customers`-Features wird eine potenzielle Fehlerquelle reduziert und der Fokus liegt auf direkt beobachtbaren und prognostizierbaren Merkmalen. Der bewusste Ausschluss dieses Features hilft dabei, die Vorhersagegenauigkeit zu maximieren und die Komplexität des Modells zu minimieren, was zu einem effizienteren und zuverlässigeren Vorhersagemodell führt.\n",
    "\n",
    "- Ob ein Geschäft geöffnet oder geschlossen ist (`Open`), hat einen direkten Einfluss auf die Verkäufe. Geschäfte, die geschlossen sind, haben keine Verkäufe. Die Korrelationsmatrix zeigt erwartungsgemäß eine hohe Korrelation mit `Sales`, da Verkäufe nur an geöffneten Tagen stattfinden können. \n",
    "\n",
    "- Promotionen (`Promo`) beeinflussen die Verkaufszahlen erheblich, indem sie mehr Kunden anziehen und den Umsatz steigern. Die Korrelationsmatrix weist darauf hin, dass Promotionen zu höheren Verkaufszahlen führen, da eine positive Korrelation mit `Sales` besteht. \n",
    "\n",
    "- Feiertage (`StateHoliday`) beeinflussen das Einkaufsverhalten der Kunden, da an staatlichen Feiertagen Geschäfte geschlossen sein oder weniger Kunden haben könnten. Die Korrelation variiert je nach Art des Feiertags, zeigt aber signifikante Zusammenhänge. \n",
    "\n",
    "- Unterschiedliche Store-Typen (`StoreType`) können unterschiedliche Verkaufsmuster haben. Größere Geschäfte oder spezielle Geschäftsmodelle könnten höhere Verkäufe generieren. Die Korrelationsmatrix zeigt, dass die Korrelation je nach Typ variiert, aber signifikante Korrelationen mit anderen wichtigen Features wie `Promo` bestehen.\n",
    "\n",
    "Die Wahl der zusätzlichen Features basiert auf ihrer logischen Relevanz und bisherigen Korrelationsanalysen. Features wie `DayOfWeek`, `Open`, `Promo`, `StateHoliday` und `StoreType` sind stark mit den Verkaufszahlen verbunden und bieten wertvolle Informationen zur Verbesserung der Modellgenauigkeit. Eine detaillierte Untersuchung der Korrelationen dieser Features mit `Sales` bestätigt ihre Bedeutung und rechtfertigt ihre Einbeziehung in das Vorhersagemodell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features (sales of the previous days/weeks)\n",
    "data = data.sort_values(by=['Store', 'Date'])\n",
    "data['lag_1'] = data.groupby('Store')['Sales'].shift(1)\n",
    "data['lag_7'] = data.groupby('Store')['Sales'].shift(7)\n",
    "\n",
    "data['lag_1'] = data.groupby(['Store', 'DayOfWeek'])['lag_1'].transform(lambda x: x.fillna(x.median()))\n",
    "data['lag_7'] = data.groupby(['Store', 'DayOfWeek'])['lag_7'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "data.drop(columns=['CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Customers', 'SchoolHoliday'], inplace=True)\n",
    "\n",
    "# Saving the cleansed data\n",
    "data.to_csv('../data/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.017209e+06\n",
       "mean     5.773026e+03\n",
       "std      3.849090e+03\n",
       "min      0.000000e+00\n",
       "25%      3.727000e+03\n",
       "50%      5.743000e+03\n",
       "75%      7.854000e+03\n",
       "max      4.155100e+04\n",
       "Name: lag_1, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lag_1'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Externe Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Wetterbedingungen können einen erheblichen Einfluss auf das Kaufverhalten von Kunden und somit auf den Umsatz der Rossmann-Stores haben. Diese Beziehung ist in vielen Branchen gut dokumentiert, da das Wetter mit dazu beiträgt, ob und wo ein Kunde einkauft. Schlechtes Wetter wie Regen und Schnee können Menschen davon abhalten, ihre Häuser zu verlassen, was zu einem Rückgang der Kundenfrequenz und damit einhergehend einem Einbruch des Umsatzes zur folge haben kann. Andererseits können angenehme Wetterbedingungen die Menschen dazu ermutigen, mehr Zeit im Freien und in Einkaufszentren zu verbringen, was den Umsatz steigern kann. Ein weiteres Argument, dafür dass das Wetter das Kaufverhalten der Kunden beeinflussen kann, ist die Art der gekauften Produkte. Verbraucher kaufen an sonnigen und heißen Tagen viel mehr Erfrischungsgetränke und Eiscreme, wohingegen an kalten Tage die Nachfrage nach warmen Getränken steigt. Auch saisonale Veränderungen wie Ferienzeiten, die oft mit spezifischen Wetterbedingungen verbunden sind, können das Kaufverhalten und die Umsatzmuster stark beeinflussen. Angesichts dieser potenziellen Einflüsse ist es sinnvoll, Wetterbedingungen als externes Feature in Verkaufsprognosemodelle zu integrieren. Durch die Berücksichtigung von Wetterdaten wie Temperatur, Niederschlag, Sonnenscheindauer und Bewölkung kann die Genauigkeit der Vorhersagemodelle verbessert werden. Dies ermöglicht eine präzisere Planung und Steuerung von Lagerbeständen, Werbemaßnahmen und Personalressourcen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
