{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# 1. Datensatz laden\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_test = pd.read_csv('y_test.csv')\n",
    "\n",
    "\n",
    "# y_train und y_test in Series umwandeln\n",
    "y_train = pd.read_csv('y_train.csv').iloc[:, 0]\n",
    "y_test = pd.read_csv('y_test.csv').iloc[:, 0]\n",
    "\n",
    "# 2. Angepasste RMSPE-Funktion\n",
    "def rmspe(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# RMSPE als Scorer definieren\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n",
    "\n",
    "# 3. Numerische und kategorische Features definieren\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'lag_1', 'lag_7']\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "categorical_features_to_encode = ['Store', 'DayOfWeek', 'StoreType', 'StateHoliday', 'Assortment']\n",
    "\n",
    "# 4. Preprocessor erstellen\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features + already_encoded_features),  \n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)  \n",
    "    ])\n",
    "\n",
    "# 5. Pipeline erstellen\n",
    "pipeline_lr = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# 6. Pipeline mit den Trainingsdaten trainieren\n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "\n",
    "# 7. Cross-Validation mit 5 Folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipeline_lr, X_train, y_train, cv=kf, scoring=rmspe_scorer, verbose=True)\n",
    "\n",
    "# Durchschnittliche RMSPE aus Cross-Validation\n",
    "mean_rmspe = np.mean(cv_scores)\n",
    "print(f'Mean RMSPE (Cross-Validation): {mean_rmspe}')\n",
    "\n",
    "# 8. Vorhersagen auf dem Testdatensatz machen\n",
    "y_pred = pipeline_lr.predict(X_test)\n",
    "\n",
    "# RMSPE auf Testdatensatz berechnen\n",
    "test_rmspe = rmspe(y_test, y_pred)\n",
    "print(f'RMSPE on Test Data: {test_rmspe}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installiere Prophet, falls noch nicht geschehen\n",
    "# !pip install prophet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer\n",
    "from prophet import Prophet\n",
    "\n",
    "# Angepasste RMSPE-Funktion, die Tage mit 0 Sales ignoriert\n",
    "def rmspe(y_true, y_pred):\n",
    "    # Nur Fälle berücksichtigen, bei denen y_true nicht 0 ist\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    \n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# Laden des Datensatzes\n",
    "data_cleaned = \"../data/cleaned_train.csv\"\n",
    "data = pd.read_csv(data_cleaned, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)\n",
    "\n",
    "# Sicherstellen, dass das Datumsformat korrekt ist\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Umwandeln der Daten in das Prophet-kompatible Format\n",
    "df_prophet = data[['Date', 'Sales']].rename(columns={'Date': 'ds', 'Sales': 'y'})\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testsets (Beispiel: Daten vor Juli 2015 zum Trainieren)\n",
    "train_data_prophet = df_prophet[df_prophet['ds'] < '2015-07-01']\n",
    "test_data_prophet = df_prophet[df_prophet['ds'] >= '2015-07-01']\n",
    "\n",
    "# Erstellen eines Prophet-Modells\n",
    "model = Prophet()\n",
    "\n",
    "# Trainieren des Prophet-Modells mit den Trainingsdaten\n",
    "model.fit(train_data_prophet)\n",
    "\n",
    "# Erstellen eines DataFrames für zukünftige Datenpunkte (Vorhersagen für die nächsten Testtage)\n",
    "future = model.make_future_dataframe(periods=len(test_data_prophet), freq='D')\n",
    "\n",
    "# Vorhersagen erstellen\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Vorhersagen anzeigen (yhat ist die vorhergesagte Sales-Wert)\n",
    "print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail())\n",
    "\n",
    "# Zusammenführen der Vorhersagen mit den tatsächlichen Werten\n",
    "forecast_with_actual = forecast[['ds', 'yhat']].merge(test_data_prophet, on='ds')\n",
    "\n",
    "# RMSPE-Bewertung berechnen\n",
    "test_rmspe_prophet = rmspe(forecast_with_actual['y'], forecast_with_actual['yhat'])\n",
    "print(\"Test RMSPE for Prophet:\", test_rmspe_prophet)\n",
    "\n",
    "# Vorhersage-Plot\n",
    "model.plot(forecast)\n",
    "\n",
    "# Komponenten-Plot (Trend, wöchentliche und jährliche Saisonalität)\n",
    "model.plot_components(forecast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Versuch K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittlicher RMSPE (KNN, Cross-Validation): -0.18428386705253738\n",
      "Test RMSPE (KNN): 0.25260392403362986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import make_scorer  # make_scorer importieren\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Laden des Datensatzes\n",
    "data_cleaned = \"../data/cleaned_train.csv\"\n",
    "data = pd.read_csv(data_cleaned, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'lag_1', 'lag_7']\n",
    "\n",
    "# Bereits encodierte Features\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "\n",
    "# Noch nicht encodierte kategorische Features\n",
    "categorical_features_to_encode = ['Store', 'DayOfWeek', 'StoreType', 'StateHoliday','Assortment']\n",
    "\n",
    "# 1. Datensatz aufteilen in Trainings- und Testdaten\n",
    "##X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Bestimme die Grenze für 80% Training und 20% Test\n",
    "train_size = int(len(df) * 0.8)\n",
    "\n",
    "# Aufteilen in Trainings- und Test-Datensätze\n",
    "train = df.iloc[:train_size]\n",
    "test = df.iloc[train_size:]\n",
    "\n",
    "# Ziel- und Eingabedaten für Training und Test\n",
    "X_train = train.drop('Sales', axis=1)\n",
    "y_train = train['Sales']\n",
    "X_test = test.drop('Sales', axis=1)\n",
    "y_test = test['Sales']\n",
    "\n",
    "# Angepasste RMSPE-Funktion, die Tage mit 0 Sales ignoriert\n",
    "def rmspe(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# RMSPE als Scorer definieren\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n",
    "\n",
    "# Erstelle den Preprocessor für numerische und kategorische Features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features + already_encoded_features),\n",
    "        ('enc', 'passthrough', already_encoded_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)\n",
    "    ])\n",
    "\n",
    "# Erstelle die Pipeline für KNN\n",
    "pipeline_knn = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', KNeighborsRegressor(n_neighbors=5))  # Du kannst hier n_neighbors anpassen\n",
    "])\n",
    "\n",
    "# Trainiere das KNN-Modell\n",
    "pipeline_knn.fit(X_train, y_train)\n",
    "\n",
    "# 5-fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores_knn = cross_val_score(pipeline_knn, X_train, y_train, cv=kf, scoring=rmspe_scorer, verbose=True)\n",
    "\n",
    "# Durchschnittlichen RMSPE berechnen\n",
    "mean_rmspe_knn = np.mean(cv_scores_knn)\n",
    "print(\"Durchschnittlicher RMSPE (KNN, Cross-Validation):\", mean_rmspe_knn)\n",
    "\n",
    "# 3. Vorhersagen auf dem Testset machen\n",
    "y_pred_knn = pipeline_knn.predict(X_test)\n",
    "\n",
    "# Test RMSPE berechnen\n",
    "test_rmspe_knn = rmspe(y_test, y_pred_knn)\n",
    "print(\"Test RMSPE (KNN):\", test_rmspe_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Versuch mit Timestamp Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import make_scorer  # make_scorer importieren\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Laden des Datensatzes\n",
    "data_cleaned = \"../data/cleaned_train.csv\"\n",
    "data = pd.read_csv(data_cleaned, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'lag_1', 'lag_7']\n",
    "\n",
    "# Bereits encodierte Features\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "\n",
    "# Noch nicht encodierte kategorische Features\n",
    "categorical_features_to_encode = ['Store', 'DayOfWeek', 'StoreType', 'StateHoliday','Assortment']\n",
    "\n",
    "# 1. Datensatz aufteilen in Trainings- und Testdaten\n",
    "##X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Bestimme die Grenze für 80% Training und 20% Test\n",
    "train_size = int(len(df) * 0.8)\n",
    "\n",
    "# Aufteilen in Trainings- und Test-Datensätze\n",
    "train = df.iloc[:train_size]\n",
    "test = df.iloc[train_size:]\n",
    "\n",
    "# Ziel- und Eingabedaten für Training und Test\n",
    "X_train = train.drop('Sales', axis=1)\n",
    "y_train = train['Sales']\n",
    "X_test = test.drop('Sales', axis=1)\n",
    "y_test = test['Sales']\n",
    "\n",
    "# Angepasste RMSPE-Funktion, die Tage mit 0 Sales ignoriert\n",
    "def rmspe(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# RMSPE als Scorer definieren\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n",
    "\n",
    "# Erstelle den Preprocessor für numerische und kategorische Features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features + already_encoded_features),\n",
    "        ('enc', 'passthrough', already_encoded_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)\n",
    "    ])\n",
    "\n",
    "# Erstelle die Pipeline für KNN\n",
    "pipeline_knn = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', KNeighborsRegressor(n_neighbors=5))  # Du kannst hier n_neighbors anpassen\n",
    "])\n",
    "\n",
    "# Trainiere das KNN-Modell\n",
    "pipeline_knn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 5-fold TimeSeries Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Cross-Validation mit TimeSeriesSplit\n",
    "cv_scores_knn = cross_val_score(pipeline_knn, X_train, y_train, cv=tscv, scoring=rmspe_scorer, verbose=True)\n",
    "\n",
    "# Durchschnittlichen RMSPE berechnen\n",
    "mean_rmspe_knn = np.mean(cv_scores_knn)\n",
    "print(\"Durchschnittlicher RMSPE (KNN, TimeSeries Cross-Validation):\", mean_rmspe_knn)\n",
    "\n",
    "# 3. Vorhersagen auf dem Testset machen\n",
    "y_pred_knn = pipeline_knn.predict(X_test)\n",
    "\n",
    "# Test RMSPE berechnen\n",
    "test_rmspe_knn = rmspe(y_test, y_pred_knn)\n",
    "print(\"Test RMSPE (KNN):\", test_rmspe_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Durchschnittlicher RMSPE ist schlechter geworden (von -0.184 auf -0.232)\n",
    "**Was es bedeutet**:\n",
    "- Der RMSPE-Wert in der zeitbasierten Cross-Validation ist höher geworden. Das bedeutet, dass das Modell auf den Trainingsdaten in der zeitlichen Cross-Validation schlechter abschneidet als zuvor in der regulären Cross-Validation.\n",
    "\n",
    "**Gründe für die Verschlechterung:**\n",
    "- Zeitabhängigkeit der Daten: Die Daten, die du modellierst, haben eine zeitliche Komponente, und das Modell hat Schwierigkeiten, die Muster über die Zeit hinweg zu verallgemeinern. Die nicht-zeitliche KFold-Cross-Validation vermischt die Zeiträume, was möglicherweise eine unrealistisch bessere Leistung ergab. Jetzt, wo die Cross-Validation die Reihenfolge respektiert, zeigt sich, dass das Modell nicht so gut verallgemeinert.\n",
    "**Trainingsmengen:** \n",
    "- Bei zeitbasierter Cross-Validation wird das Modell in den ersten Folds mit einer kleineren Datenmenge trainiert (weil frühere Zeitpunkte für das Training und spätere für das Testen verwendet werden). Das kann zu schlechteren Ergebnissen führen, da das Modell mit weniger Daten trainiert wird.\n",
    "\n",
    "\n",
    "## 2. Vergleich mit dem Test RMSPE (0.253)\n",
    "\n",
    "- Der RMSPE aus der zeitbasierten Cross-Validation (0.232) liegt immer noch unter dem RMSPE auf dem Testset (0.253), was bedeutet, dass das Modell immer noch tendenziell schlechter auf den Testdaten abschneidet, aber die Werte sind näher beieinander.\n",
    "\n",
    "**Was das bedeutet:** \n",
    "- Die zeitbasierte Cross-Validation scheint jetzt eine realistischere Abschätzung der Modellleistung zu liefern, da die Abweichung zwischen dem RMSPE aus der Cross-Validation und dem Test-RMSPE kleiner geworden ist. Dies deutet darauf hin, dass die nicht-zeitliche Cross-Validation das Modell möglicherweise überoptimistisch bewertet hat. (Overfitting?)\n",
    "\n",
    "\n",
    "## Fazit:\n",
    "- Die Verschlechterung des RMSPE nach Einführung der zeitbasierten Cross-Validation ist ein Hinweis darauf, dass das Modell Schwierigkeiten hat, Muster in zeitlich sortierten Daten zu lernen.\n",
    "- Der Unterschied zwischen der Cross-Validation-Leistung (0.232) und der Testleistung (0.253) ist jedoch kleiner geworden, was bedeutet, dass die zeitbasierte Cross-Validation eine realistischere Abschätzung der Modellleistung bietet.\n",
    "- Möglicherweise musst du das Modell weiter verbessern, insbesondere um die Zeitabhängigkeit der Daten besser zu erfassen, z. B. durch Feature-Engineering (Hinzufügen von Zeittrends oder saisonalen Mustern) oder durch den Einsatz von Modellen, die sich besser für zeitliche Daten eignen, wie z. B. ARIMA, Prophet, oder Recurrent Neural Networks (RNNs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Versuch Hyperparametertuning und Feature Engineering zur Verbesserung des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittlicher RMSPE (KNN, TimeSeries Cross-Validation): -0.2322984809227074\n",
      "Test RMSPE (KNN): 0.25260392403362986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Laden des Datensatzes\n",
    "data_cleaned = \"../data/cleaned_train.csv\"\n",
    "data = pd.read_csv(data_cleaned, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'lag_1', 'lag_7']\n",
    "\n",
    "# Bereits encodierte Features\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "\n",
    "# Noch nicht encodierte kategorische Features\n",
    "categorical_features_to_encode = ['Store', 'DayOfWeek', 'StoreType', 'StateHoliday','Assortment']\n",
    "\n",
    "# 1. Datensatz aufteilen in Trainings- und Testdaten\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Feature Engineering: Moving Averages und Interaktionen\n",
    "X['MA_7'] = data['Sales'].rolling(window=7).mean().shift(1)  # 7-Tages Moving Average\n",
    "X['MA_30'] = data['Sales'].rolling(window=30).mean().shift(1)  # 30-Tages Moving Average\n",
    "X['Promo_Open_Interaction'] = X['Promo'] * X['Open']  # Interaktion zwischen Promo und Open\n",
    "\n",
    "# Entfernen von NaN-Werten, die durch Moving Averages entstanden sind\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "# Bestimme die Grenze für 80% Training und 20% Test\n",
    "train_size = int(len(df) * 0.8)\n",
    "\n",
    "# Aufteilen in Trainings- und Test-Datensätze\n",
    "train = df.iloc[:train_size]\n",
    "test = df.iloc[train_size:]\n",
    "\n",
    "# Ziel- und Eingabedaten für Training und Test\n",
    "X_train = train.drop('Sales', axis=1)\n",
    "y_train = train['Sales']\n",
    "X_test = test.drop('Sales', axis=1)\n",
    "y_test = test['Sales']\n",
    "\n",
    "# Angepasste RMSPE-Funktion, die Tage mit 0 Sales ignoriert\n",
    "def rmspe(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# RMSPE als Scorer definieren\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n",
    "\n",
    "# Erstelle den Preprocessor für numerische und kategorische Features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features + already_encoded_features),\n",
    "        ('enc', 'passthrough', already_encoded_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)\n",
    "    ])\n",
    "\n",
    "# Erstelle die Pipeline für KNN\n",
    "pipeline_knn = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', KNeighborsRegressor(n_neighbors=5))  # Du kannst hier n_neighbors anpassen\n",
    "])\n",
    "\n",
    "# Hyperparameter-Tuning mit GridSearchCV\n",
    "param_grid = {\n",
    "    'model__n_neighbors': [3, 5, 10, 15],   # Verschiedene Werte für k\n",
    "    'model__weights': ['uniform', 'distance'],  # Gewichtete oder uniforme Nachbarn\n",
    "    'model__metric': ['euclidean', 'manhattan']  # Verschiedene Distanzmetriken\n",
    "}\n",
    "\n",
    "# Trainiere das KNN-Modell\n",
    "pipeline_knn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 5-fold TimeSeries Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Cross-Validation mit TimeSeriesSplit\n",
    "cv_scores_knn = cross_val_score(pipeline_knn, X_train, y_train, cv=tscv, scoring=rmspe_scorer, verbose=True)\n",
    "\n",
    "# Durchschnittlichen RMSPE berechnen\n",
    "mean_rmspe_knn = np.mean(cv_scores_knn)\n",
    "print(\"Durchschnittlicher RMSPE (KNN, TimeSeries Cross-Validation):\", mean_rmspe_knn)\n",
    "\n",
    "# 3. Vorhersagen auf dem Testset machen\n",
    "y_pred_knn = pipeline_knn.predict(X_test)\n",
    "\n",
    "# Test RMSPE berechnen\n",
    "test_rmspe_knn = rmspe(y_test, y_pred_knn)\n",
    "print(\"Test RMSPE (KNN):\", test_rmspe_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Versuch mit Lag Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden des Datensatzes\n",
    "data_cleaned = \"../data/cleaned_train.csv\"\n",
    "data = pd.read_csv(data_cleaned, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)\n",
    "# Sicherstellen, dass die Datums-Spalte korrekt ist\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "# Jahr, Monat, Tag und Wochentag extrahieren\n",
    "data['year'] = data['Date'].dt.year\n",
    "data['month'] = data['Date'].dt.month\n",
    "data['day'] = data['Date'].dt.day\n",
    "data['day_of_week'] = data['Date'].dt.weekday  # Montag = 0, Sonntag = 6\n",
    "# Entferne die ursprüngliche Datums-Spalte\n",
    "data = data.drop('Date', axis=1)\n",
    "\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'lag_1', 'lag_7']\n",
    "\n",
    "# Bereits encodierte Features\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "\n",
    "# Noch nicht encodierte kategorische Features\n",
    "categorical_features_to_encode = ['Store', 'DayOfWeek', 'StoreType', 'StateHoliday','Assortment']\n",
    "\n",
    "# 1. Datensatz aufteilen in Trainings- und Testdaten\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering mit lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Moving Averages und Interaktionen\n",
    "#X['MA_7'] = data['Sales'].rolling(window=7).mean().shift(1)  # 7-Tages Moving Average\n",
    "#X['MA_30'] = data['Sales'].rolling(window=30).mean().shift(1)  # 30-Tages Moving Average\n",
    "#X['Promo_Open_Interaction'] = X['Promo'] * X['Open']  # Interaktion zwischen Promo und Open\n",
    "\n",
    "# Entfernen von NaN-Werten, die durch Moving Averages entstanden sind\n",
    "#X.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m iterative_forecast(pipeline_knn, X_fold_train_preprocessed, y_fold_train, X_fold_test)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# RMSPE berechnen und speichern\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m rmspe_score \u001b[38;5;241m=\u001b[39m \u001b[43mrmspe\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_fold_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m rmspe_scores\u001b[38;5;241m.\u001b[39mappend(rmspe_score)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSPE for Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmspe_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m, in \u001b[0;36mrmspe\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      3\u001b[0m mask \u001b[38;5;241m=\u001b[39m y_true \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m y_true_filtered \u001b[38;5;241m=\u001b[39m y_true[mask]\n\u001b[1;32m----> 5\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m \u001b[43my_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mmean(((y_true_filtered \u001b[38;5;241m-\u001b[39m y_pred_filtered) \u001b[38;5;241m/\u001b[39m y_true_filtered) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not Series"
     ]
    }
   ],
   "source": [
    "# Verbesserte iterative Vorhersagefunktion (mit Berücksichtigung von Lag- und zusätzlichen Features)\n",
    "def iterative_forecast(pipeline, X_fold_train, y_fold_train, X_fold_val):\n",
    "    # Trainiere das Modell mit allen Features\n",
    "    pipeline.named_steps['model'].fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Vorhersagen auf Basis der Testdaten\n",
    "    predictions = []\n",
    "    last_known_sales = list(y_fold_train[-7:])  # Letzte 30 Tage tatsächlicher Sales-Daten\n",
    "    \n",
    "    # Iteriere über die Zeilen von X_fold_val\n",
    "    for index, row in X_fold_val.iterrows():\n",
    "        try:\n",
    "            # Lag-Features für den nächsten Tag berechnen\n",
    "            row[\"lag_1\"] = last_known_sales[-1]  # Lag-1 ist der zuletzt vorhergesagte Wert\n",
    "            row[\"lag_7\"] = last_known_sales[-7] if len(last_known_sales) >= 7 else np.nan  # Lag-7 ist 7 Tage zurück\n",
    "            #row[\"lag_30\"] = last_known_sales[-30] if len(last_known_sales) >= 30 else np.nan  # Lag-30 ist 30 Tage zurück\n",
    "        except IndexError as e:\n",
    "            print(f\"Error in creating lag features for row {index}: {e}\")\n",
    "            row[\"lag_1\"] = np.nan\n",
    "            row[\"lag_7\"] = np.nan\n",
    "            #row[\"lag_30\"] = np.nan\n",
    "        \n",
    "        # Wandeln der Zeile in einen DataFrame, um den Preprocessing-Schritt durchzuführen\n",
    "        row = row.to_frame().T\n",
    "        \n",
    "        # Wende das Preprocessing an\n",
    "        row_preprocessed = pipeline.named_steps['preprocessor'].transform(row)\n",
    "        \n",
    "        # Vorhersage für den nächsten Tag\n",
    "        pred = pipeline.named_steps['model'].predict(row_preprocessed)\n",
    "        predictions.append(pred[0])  # pred ist ein Array, daher pred[0]\n",
    "        \n",
    "        # Update der letzten bekannten Sales-Daten\n",
    "        last_known_sales.append(pred[0])\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Durchführung der Kreuzvalidierung auf den Trainingsdaten\n",
    "rmspe_scores = []  # Liste zur Speicherung der RMSPE-Scores\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(X_train)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Train- und Testdaten für diesen Fold\n",
    "    X_fold_train = X_train.iloc[train_index]\n",
    "    X_fold_test = X_train.iloc[test_index]\n",
    "    y_fold_train = y_train.iloc[train_index]\n",
    "    y_fold_test = y_train.iloc[test_index]\n",
    "    \n",
    "    # Preprocessing auf die Train- und Testdaten anwenden\n",
    "    X_fold_train_preprocessed = pipeline_knn.named_steps['preprocessor'].fit_transform(X_fold_train)\n",
    "    X_fold_test_preprocessed = pipeline_knn.named_steps['preprocessor'].transform(X_fold_test)\n",
    "    \n",
    "    # Iterative Vorhersage über die Testperiode\n",
    "    y_pred = iterative_forecast(pipeline_knn, X_fold_train_preprocessed, y_fold_train, X_fold_test)\n",
    "    \n",
    "    # RMSPE berechnen und speichern\n",
    "    rmspe_score = rmspe(y_fold_test, y_pred)\n",
    "    rmspe_scores.append(rmspe_score)\n",
    "    \n",
    "    print(f\"RMSPE for Fold {fold + 1}: {rmspe_score}\")\n",
    "\n",
    "# Gesamtergebnisse\n",
    "print(f\"Durchschnittliche RMSPE über alle Folds: {np.mean(rmspe_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bestimme die Grenze für 80% Training und 20% Test\n",
    "train_size = int(len(df) * 0.8)\n",
    "\n",
    "# Aufteilen in Trainings- und Test-Datensätze\n",
    "train = df.iloc[:train_size]\n",
    "test = df.iloc[train_size:]\n",
    "\n",
    "# Ziel- und Eingabedaten für Training und Test\n",
    "X_train = train.drop('Sales', axis=1)\n",
    "y_train = train['Sales']\n",
    "X_test = test.drop('Sales', axis=1)\n",
    "y_test = test['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angepasste RMSPE-Funktion, die Tage mit 0 Sales ignoriert\n",
    "def rmspe(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# RMSPE als Scorer definieren\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n",
    "\n",
    "# Erstelle den Preprocessor für numerische und kategorische Features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features + already_encoded_features),\n",
    "        ('enc', 'passthrough', already_encoded_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier n_neighbors anpassen, wenn das Modell überanpasst ist (Overfitting), dann n_neighbors erhöhen.\n",
    "Wenn das Modell unteranpasst ist (Underfitting), dann n_neighbors verringern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle die Pipeline für KNN\n",
    "pipeline_knn = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', KNeighborsRegressor(n_neighbors=5))  # n_neighbors anpassen\n",
    "])\n",
    "\n",
    "# Hyperparameter-Tuning mit GridSearchCV\n",
    "param_grid = {\n",
    "    'model__n_neighbors': [3, 5, 10, 15],   # Verschiedene Werte für k\n",
    "    'model__weights': ['uniform', 'distance'],  # Gewichtete oder uniforme Nachbarn\n",
    "    'model__metric': ['euclidean', 'manhattan']  # Verschiedene Distanzmetriken\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittlicher RMSPE (KNN, TimeSeries Cross-Validation): -0.2322984809227074\n",
      "Test RMSPE (KNN): 0.25260392403362986\n"
     ]
    }
   ],
   "source": [
    "# Trainiere das KNN-Modell\n",
    "pipeline_knn.fit(X_train, y_train)\n",
    "\n",
    "# 5-fold TimeSeries Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Cross-Validation mit TimeSeriesSplit\n",
    "cv_scores_knn = cross_val_score(pipeline_knn, X_train, y_train, cv=tscv, scoring=rmspe_scorer, verbose=True)\n",
    "\n",
    "# Durchschnittlichen RMSPE berechnen\n",
    "mean_rmspe_knn = np.mean(cv_scores_knn)\n",
    "print(\"Durchschnittlicher RMSPE (KNN, TimeSeries Cross-Validation):\", mean_rmspe_knn)\n",
    "\n",
    "# 3. Vorhersagen auf dem Testset machen\n",
    "y_pred_knn = pipeline_knn.predict(X_test)\n",
    "\n",
    "# Test RMSPE berechnen\n",
    "test_rmspe_knn = rmspe(y_test, y_pred_knn)\n",
    "print(\"Test RMSPE (KNN):\", test_rmspe_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittlicher RMSPE (KNN, TimeSeries Cross-Validation): -0.22956527788071565\n",
      "Fold 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2200\\2704722138.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[0mX_fold_train_preprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline_knn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preprocessor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fold_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[0mX_fold_test_preprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline_knn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preprocessor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fold_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;31m# Iterative Vorhersage über die Testperiode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miterative_forecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_fold_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_fold_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_fold_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;31m# RMSPE berechnen und speichern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[0mrmspe_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmspe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_fold_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2200\\2704722138.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(pipeline, X_fold_train, y_fold_train, X_fold_val)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0miterative_forecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_fold_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_fold_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_fold_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# Trainiere das Modell mit allen Features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fold_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_fold_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;31m# Vorhersagen auf Basis der Testdaten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1473\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neighbors\\_regression.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnearest\u001b[0m \u001b[0mneighbors\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \"\"\"\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"requires_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNeighborsBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m                 X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    476\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    646\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1269\u001b[0m         raise ValueError(\n\u001b[0;32m   1270\u001b[0m             \u001b[1;33mf\"\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mestimator_name\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m requires y to be passed, but the target y is None\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1273\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1274\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1004\u001b[0m                         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1008\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1009\u001b[0m                 raise ValueError(\n\u001b[0;32m   1010\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m                 \u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     def __array__(\n\u001b[0;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2154\u001b[0m         if (\n\u001b[0;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'a'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Laden des Datensatzes\n",
    "data_cleaned = \"../data/cleaned_train.csv\"\n",
    "data = pd.read_csv(data_cleaned, delimiter=\",\", encoding=\"latin\", header=0, thousands=\",\", decimal='.', low_memory=False)\n",
    "# Sicherstellen, dass die Datums-Spalte korrekt ist\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "# Jahr, Monat, Tag und Wochentag extrahieren\n",
    "data['year'] = data['Date'].dt.year\n",
    "data['month'] = data['Date'].dt.month\n",
    "data['day'] = data['Date'].dt.day\n",
    "data['day_of_week'] = data['Date'].dt.weekday  # Montag = 0, Sonntag = 6\n",
    "# Entferne die ursprüngliche Datums-Spalte\n",
    "data = data.drop('Date', axis=1)\n",
    "\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = data.drop('Sales', axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "\n",
    "# Definiere die numerischen und kategorischen Features\n",
    "numerical_features = ['year', 'month', 'day', 'week_of_year', 'lag_1', 'lag_7']\n",
    "# Bereits encodierte Features\n",
    "already_encoded_features = ['Open', 'Promo', 'promo2']\n",
    "# Noch nicht encodierte kategorische Features\n",
    "categorical_features_to_encode = ['Store', 'DayOfWeek', 'StoreType', 'StateHoliday','Assortment']\n",
    "\n",
    "\n",
    "# Bestimme die Grenze für 80% Training und 20% Test\n",
    "train_size = int(len(data) * 0.8)\n",
    "# Aufteilen in Trainings- und Test-Datensätze\n",
    "train = data.iloc[:train_size]\n",
    "test = data.iloc[train_size:]\n",
    "# Ziel- und Eingabedaten für Training und Test\n",
    "X_train = train.drop('Sales', axis=1)\n",
    "y_train = train['Sales']\n",
    "X_test = test.drop('Sales', axis=1)\n",
    "y_test = test['Sales']\n",
    "\n",
    "\n",
    "# Erstelle den Preprocessor für numerische und kategorische Features (ohne Datumsextraktion)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),  # Skalierung für numerische Features\n",
    "        ('enc', 'passthrough', already_encoded_features),  # Bereits encodierte Features durchschleusen\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_to_encode)  # Encodieren von kategorischen Features\n",
    "    ])\n",
    "\n",
    "# Erstelle die Pipeline für KNN\n",
    "pipeline_knn = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', KNeighborsRegressor(n_neighbors=5))  # Standardwert für n_neighbors\n",
    "])\n",
    "\n",
    "# Verbesserte iterative Vorhersagefunktion (mit Berücksichtigung von Lag- und zusätzlichen Features)\n",
    "def iterative_forecast(pipeline, X_fold_train, y_fold_train, X_fold_val):\n",
    "    # Trainiere das Modell mit allen Features\n",
    "    pipeline.named_steps['model'].fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Vorhersagen auf Basis der Testdaten\n",
    "    predictions = []\n",
    "    last_known_sales = list(y_fold_train[-7:])  # Letzte 7 Tage tatsächlicher Sales-Daten\n",
    "    \n",
    "    # Iteriere über die Zeilen von X_fold_val\n",
    "    for index, row in X_fold_val.iterrows():\n",
    "        try:\n",
    "            # Lag-Features für den nächsten Tag berechnen\n",
    "            row[\"lag_1\"] = last_known_sales[-1]  # Lag-1 ist der zuletzt vorhergesagte Wert\n",
    "            row[\"lag_7\"] = last_known_sales[-7] if len(last_known_sales) >= 7 else 0  # Lag-7 ist 7 Tage zurück, Default 0\n",
    "        except IndexError as e:\n",
    "            print(f\"Error in creating lag features for row {index}: {e}\")\n",
    "            row[\"lag_1\"] = np.nan\n",
    "            row[\"lag_7\"] = np.nan\n",
    "        \n",
    "        # Wandeln der Zeile in einen DataFrame, um den Preprocessing-Schritt durchzuführen\n",
    "        row = row.to_frame().T\n",
    "        \n",
    "        # Wende das Preprocessing an\n",
    "        row_preprocessed = pipeline.named_steps['preprocessor'].transform(row)\n",
    "        \n",
    "        # Vorhersage für den nächsten Tag\n",
    "        pred = pipeline.named_steps['model'].predict(row_preprocessed)\n",
    "        predictions.append(pred[0])  # pred ist ein Array, daher pred[0]\n",
    "        \n",
    "        # Update der letzten bekannten Sales-Daten\n",
    "        last_known_sales.append(pred[0])\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Angepasste RMSPE-Funktion, die Tage mit 0 Sales ignoriert\n",
    "def rmspe(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    return np.sqrt(np.mean(((y_true_filtered - y_pred_filtered) / y_true_filtered) ** 2))\n",
    "\n",
    "# RMSPE als Scorer definieren\n",
    "rmspe_scorer = make_scorer(rmspe, greater_is_better=False)\n",
    "\n",
    "# Hyperparameter-Tuning mit GridSearchCV\n",
    "param_grid = {\n",
    "    'model__n_neighbors': [3, 5, 10, 15],\n",
    "    'model__weights': ['uniform', 'distance'],\n",
    "    'model__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# 5-fold TimeSeries Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "# Cross-Validation mit TimeSeriesSplit\n",
    "cv_scores_knn = cross_val_score(pipeline_knn, X_train, y_train, cv=tscv, scoring=rmspe_scorer, verbose=True)\n",
    "# Durchschnittlichen RMSPE berechnen\n",
    "mean_rmspe_knn = np.mean(cv_scores_knn)\n",
    "print(\"Durchschnittlicher RMSPE (KNN, TimeSeries Cross-Validation):\", mean_rmspe_knn)\n",
    "\n",
    "# Durchführung der Kreuzvalidierung auf den Trainingsdaten\n",
    "rmspe_scores = []  # Liste zur Speicherung der RMSPE-Scores\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(X_train)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Train- und Testdaten für diesen Fold\n",
    "    X_fold_train = X_train.iloc[train_index]\n",
    "    X_fold_test = X_train.iloc[test_index]\n",
    "    y_fold_train = y_train.iloc[train_index]\n",
    "    y_fold_test = y_train.iloc[test_index]\n",
    "    \n",
    "    # Preprocessing auf die Train- und Testdaten anwenden\n",
    "    X_fold_train_preprocessed = pipeline_knn.named_steps['preprocessor'].fit_transform(X_fold_train)\n",
    "    X_fold_test_preprocessed = pipeline_knn.named_steps['preprocessor'].transform(X_fold_test)\n",
    "    \n",
    "    # Iterative Vorhersage über die Testperiode\n",
    "    y_pred = iterative_forecast(pipeline_knn, X_fold_train, y_fold_train, X_fold_test)\n",
    "    \n",
    "    # RMSPE berechnen und speichern\n",
    "    rmspe_score = rmspe(y_fold_test, y_pred)\n",
    "    rmspe_scores.append(rmspe_score)\n",
    "    \n",
    "    print(f\"RMSPE for Fold {fold + 1}: {rmspe_score}\")\n",
    "\n",
    "# Gesamtergebnisse\n",
    "print(f\"Durchschnittliche RMSPE über alle Folds: {np.mean(rmspe_scores)}\")\n",
    "\n",
    "# GridSearchCV anwenden\n",
    "grid_search_knn = GridSearchCV(pipeline_knn, param_grid, cv=tscv, scoring=rmspe_scorer, verbose=True)\n",
    "\n",
    "# Führe die Suche aus\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Beste Parameter ausgeben\n",
    "print(\"Beste Parameter: \", grid_search_knn.best_params_)\n",
    "\n",
    "# Vorhersagen auf dem Testset mit den besten Parametern\n",
    "y_pred_knn_best = grid_search_knn.predict(X_test)\n",
    "\n",
    "# Test RMSPE berechnen\n",
    "test_rmspe_knn_best = rmspe(y_test, y_pred_knn_best)\n",
    "print(\"Test RMSPE (KNN, beste Parameter):\", test_rmspe_knn_best)\n",
    "\n",
    "# 3. Vorhersagen auf dem Testset machen\n",
    "y_pred_knn = pipeline_knn.predict(X_test)\n",
    "\n",
    "# Test RMSPE berechnen\n",
    "test_rmspe_knn = rmspe(y_test, y_pred_knn)\n",
    "print(\"Test RMSPE (KNN):\", test_rmspe_knn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
